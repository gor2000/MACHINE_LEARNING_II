{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "_OKK2VwBbP81",
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.620536Z",
     "start_time": "2023-09-21T18:05:53.529235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Mock Midterm Exercise"
   ],
   "metadata": {
    "id": "VoFYQVQ0bVCN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise you will have to implement code in the sections inside *Fill with Your Code* (*Load Data*, *Data Preprocessing* and *Create Model*) create a model to predict the column *exitus* in the dataset given. The dataset is already split into train, validation, and test subsets. To see to which subset belong each observation, you need to check the *dataset* column.\n",
    "\n",
    "The code that is already written in this notebook **CANNOT BE CHANGED**. You can only add code in the *Fill with Your Code* section.\n",
    "\n",
    "You must achieve in the last cell of this notebook an **AUC over test of at least 0.93**."
   ],
   "metadata": {
    "id": "xdYg4_U3bYH8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fill With Your Code"
   ],
   "metadata": {
    "id": "_lpuKCkfb9do"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [1] Load Data"
   ],
   "metadata": {
    "id": "66HBtc2Cbpm_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dat = pd.read_csv('../data/dat.csv', sep = \",\")"
   ],
   "metadata": {
    "id": "EtxuaDPHbWj1",
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.706687Z",
     "start_time": "2023-09-21T18:05:53.579897Z"
    }
   },
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dat"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Qq_JqH9bev9L",
    "outputId": "95b4918a-7f25-4969-9592-bc4d6b7649bd",
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.707958Z",
     "start_time": "2023-09-21T18:05:53.614599Z"
    }
   },
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "          date  severity  mortality_ratio      age  num_proc  ambulatory  \\\n0      2016-01       NaN         0.408730  12596.0      21.0         0.0   \n1      2016-01       NaN         0.306931  20973.0      22.0         NaN   \n2      2016-01       4.0         0.278481  19611.0      19.0         NaN   \n3      2016-01       3.0         0.150289  13583.0      22.0         NaN   \n4      2016-01       1.0         0.016573  18042.0       2.0         NaN   \n...        ...       ...              ...      ...       ...         ...   \n32701  2016-12       2.0         0.028365  23619.0       2.0         NaN   \n32702  2016-12       1.0         0.000606   3935.0       1.0         NaN   \n32703  2016-12       NaN         0.040452  30163.0       4.0         NaN   \n32704  2016-12       NaN         0.000000  29012.0       4.0         NaN   \n32705  2016-12       NaN         0.000000  13244.0       1.0         NaN   \n\n       origin  expected_length tip_grd  tip_adm  exitus dataset  \n0         NaN            151.0       Q      1.0       0   train  \n1         NaN             99.0       Q      1.0       0   train  \n2         NaN             87.0     NaN      1.0       0   train  \n3         NaN            100.0       Q      NaN       0   train  \n4         NaN             44.0       Q      1.0       0   train  \n...       ...              ...     ...      ...     ...     ...  \n32701     NaN              2.0     NaN      1.0       0    test  \n32702     1.0              2.0       M      1.0       0    test  \n32703     NaN              2.0       M      NaN       0    test  \n32704     NaN              0.0     NaN      1.0       0    test  \n32705     NaN              0.0       Q      1.0       0    test  \n\n[32706 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.408730</td>\n      <td>12596.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>151.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.306931</td>\n      <td>20973.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>4.0</td>\n      <td>0.278481</td>\n      <td>19611.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>3.0</td>\n      <td>0.150289</td>\n      <td>13583.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.0</td>\n      <td>Q</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01</td>\n      <td>1.0</td>\n      <td>0.016573</td>\n      <td>18042.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>2016-12</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.040452</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [2]  Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "dat.drop('date', axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.737092Z",
     "start_time": "2023-09-21T18:05:53.620941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "cat_var = ['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
    "non_cat_var = list(set(dat.columns) - set(cat_var))\n",
    "num_var = list(set(dat.columns) - set(cat_var) - {'dataset', 'exitus'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.737727Z",
     "start_time": "2023-09-21T18:05:53.624550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio     True\nage                 True\nnum_proc            True\nambulatory          True\norigin              True\nexpected_length     True\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.737934Z",
     "start_time": "2023-09-21T18:05:53.630759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory          True\norigin              True\nexpected_length    False\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer as MICE # pip install fancyimpute\n",
    "# 3) Define \"model\"\n",
    "model = MICE()\n",
    "\n",
    "# 4) Train \"model\"\n",
    "model.fit(dat[num_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) \"Predict\"\n",
    "dat[num_var] = model.transform(dat[num_var])\n",
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.803184Z",
     "start_time": "2023-09-21T18:05:53.638791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "severity      14491\nambulatory    21528\norigin        14359\ntip_grd        9492\ntip_adm        4255\ndtype: int64"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[cat_var][dat['dataset'] == 'train'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.820984Z",
     "start_time": "2023-09-21T18:05:53.764005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "severity      0\nambulatory    0\norigin        0\ntip_grd       0\ntip_adm       0\ndtype: int64"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.loc[dat['dataset'] == 'train', cat_var] = dat.loc[dat['dataset'] == 'train', cat_var].fillna('UNKNOWN')\n",
    "dat[cat_var][dat['dataset'] == 'train'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.840784Z",
     "start_time": "2023-09-21T18:05:53.782506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "dat[cat_var] = dat[cat_var].astype('str')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.842163Z",
     "start_time": "2023-09-21T18:05:53.809977Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False, drop='first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(dat[cat_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(dat[cat_var]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "dat = pd.concat((dat[non_cat_var], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.902267Z",
     "start_time": "2023-09-21T18:05:53.838079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "       exitus  num_proc  mortality_ratio      age  expected_length dataset  \\\n0           0      21.0         0.408730  12596.0            151.0   train   \n1           0      22.0         0.306931  20973.0             99.0   train   \n2           0      19.0         0.278481  19611.0             87.0   train   \n3           0      22.0         0.150289  13583.0            100.0   train   \n4           0       2.0         0.016573  18042.0             44.0   train   \n...       ...       ...              ...      ...              ...     ...   \n32701       0       2.0         0.028365  23619.0              2.0    test   \n32702       0       1.0         0.000606   3935.0              2.0    test   \n32703       0       4.0         0.040452  30163.0              2.0    test   \n32704       0       4.0         0.000000  29012.0              0.0    test   \n32705       0       1.0         0.000000  13244.0              0.0    test   \n\n       severity_2.0  severity_3.0  severity_4.0  severity_UNKNOWN  ...  \\\n0               0.0           0.0           0.0               1.0  ...   \n1               0.0           0.0           0.0               1.0  ...   \n2               0.0           0.0           1.0               0.0  ...   \n3               0.0           1.0           0.0               0.0  ...   \n4               0.0           0.0           0.0               0.0  ...   \n...             ...           ...           ...               ...  ...   \n32701           1.0           0.0           0.0               0.0  ...   \n32702           0.0           0.0           0.0               0.0  ...   \n32703           0.0           0.0           0.0               0.0  ...   \n32704           0.0           0.0           0.0               0.0  ...   \n32705           0.0           0.0           0.0               0.0  ...   \n\n       origin_9.0  origin_UNKNOWN  origin_nan  tip_grd_Q  tip_grd_UNKNOWN  \\\n0             0.0             1.0         0.0        1.0              0.0   \n1             0.0             1.0         0.0        1.0              0.0   \n2             0.0             1.0         0.0        0.0              1.0   \n3             0.0             1.0         0.0        1.0              0.0   \n4             0.0             1.0         0.0        1.0              0.0   \n...           ...             ...         ...        ...              ...   \n32701         0.0             0.0         1.0        0.0              0.0   \n32702         0.0             0.0         0.0        0.0              0.0   \n32703         0.0             0.0         1.0        0.0              0.0   \n32704         0.0             0.0         1.0        0.0              0.0   \n32705         0.0             0.0         1.0        1.0              0.0   \n\n       tip_grd_nan  tip_adm_2.0  tip_adm_3.0  tip_adm_UNKNOWN  tip_adm_nan  \n0              0.0          0.0          0.0              0.0          0.0  \n1              0.0          0.0          0.0              0.0          0.0  \n2              0.0          0.0          0.0              0.0          0.0  \n3              0.0          0.0          0.0              1.0          0.0  \n4              0.0          0.0          0.0              0.0          0.0  \n...            ...          ...          ...              ...          ...  \n32701          1.0          0.0          0.0              0.0          0.0  \n32702          0.0          0.0          0.0              0.0          0.0  \n32703          0.0          0.0          0.0              0.0          1.0  \n32704          1.0          0.0          0.0              0.0          0.0  \n32705          0.0          0.0          0.0              0.0          0.0  \n\n[32706 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exitus</th>\n      <th>num_proc</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>expected_length</th>\n      <th>dataset</th>\n      <th>severity_2.0</th>\n      <th>severity_3.0</th>\n      <th>severity_4.0</th>\n      <th>severity_UNKNOWN</th>\n      <th>...</th>\n      <th>origin_9.0</th>\n      <th>origin_UNKNOWN</th>\n      <th>origin_nan</th>\n      <th>tip_grd_Q</th>\n      <th>tip_grd_UNKNOWN</th>\n      <th>tip_grd_nan</th>\n      <th>tip_adm_2.0</th>\n      <th>tip_adm_3.0</th>\n      <th>tip_adm_UNKNOWN</th>\n      <th>tip_adm_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>21.0</td>\n      <td>0.408730</td>\n      <td>12596.0</td>\n      <td>151.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>0.306931</td>\n      <td>20973.0</td>\n      <td>99.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>19.0</td>\n      <td>0.278481</td>\n      <td>19611.0</td>\n      <td>87.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>22.0</td>\n      <td>0.150289</td>\n      <td>13583.0</td>\n      <td>100.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.016573</td>\n      <td>18042.0</td>\n      <td>44.0</td>\n      <td>train</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>test</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>3935.0</td>\n      <td>2.0</td>\n      <td>test</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0.040452</td>\n      <td>30163.0</td>\n      <td>2.0</td>\n      <td>test</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>0</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>29012.0</td>\n      <td>0.0</td>\n      <td>test</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>13244.0</td>\n      <td>0.0</td>\n      <td>test</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 29 columns</p>\n</div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.931018Z",
     "start_time": "2023-09-21T18:05:53.903243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "bALdZkw9dzzv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [3] Create Model"
   ],
   "metadata": {
    "id": "5BczaKLlcKTl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor\n",
    "from sklearn.metrics import roc_auc_score as metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.944259Z",
     "start_time": "2023-09-21T18:05:53.928733Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_estimators_values = [10, 100, 1000]\n",
    "max_features_values = [2, 5, 10]\n",
    "max_samples_values = [10, 100, 1000, dat[dat['dataset'] == 'train'].shape[0]]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:05:53.944823Z",
     "start_time": "2023-09-21T18:05:53.936836Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1\n",
      "Metric train = 0.49 - Metric validation = 0.50.\n",
      "Iteration = 2\n",
      "Metric train = 0.86 - Metric validation = 0.73.\n",
      "Iteration = 3\n",
      "Metric train = 0.89 - Metric validation = 0.83.\n",
      "Iteration = 4\n",
      "Metric train = 1.00 - Metric validation = 0.81.\n",
      "Iteration = 5\n",
      "Metric train = 0.88 - Metric validation = 0.86.\n",
      "Iteration = 6\n",
      "Metric train = 0.93 - Metric validation = 0.92.\n",
      "Iteration = 7\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteration = 8\n",
      "Metric train = 1.00 - Metric validation = 0.92.\n",
      "Iteration = 9\n",
      "Metric train = 0.93 - Metric validation = 0.92.\n",
      "Iteration = 10\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteration = 11\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteration = 12\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n",
      "Iteration = 13\n",
      "Metric train = 0.56 - Metric validation = 0.55.\n",
      "Iteration = 14\n",
      "Metric train = 0.88 - Metric validation = 0.88.\n",
      "Iteration = 15\n",
      "Metric train = 0.90 - Metric validation = 0.85.\n",
      "Iteration = 16\n",
      "Metric train = 1.00 - Metric validation = 0.84.\n",
      "Iteration = 17\n",
      "Metric train = 0.90 - Metric validation = 0.89.\n",
      "Iteration = 18\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteration = 19\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteration = 20\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n",
      "Iteration = 21\n",
      "Metric train = 0.93 - Metric validation = 0.92.\n",
      "Iteration = 22\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteration = 23\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteration = 24\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n",
      "Iteration = 25\n",
      "Metric train = 0.78 - Metric validation = 0.78.\n",
      "Iteration = 26\n",
      "Metric train = 0.88 - Metric validation = 0.87.\n",
      "Iteration = 27\n",
      "Metric train = 0.90 - Metric validation = 0.88.\n",
      "Iteration = 28\n",
      "Metric train = 1.00 - Metric validation = 0.86.\n",
      "Iteration = 29\n",
      "Metric train = 0.92 - Metric validation = 0.91.\n",
      "Iteration = 30\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteration = 31\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteration = 32\n",
      "Metric train = 1.00 - Metric validation = 0.92.\n",
      "Iteration = 33\n",
      "Metric train = 0.93 - Metric validation = 0.93.\n",
      "Iteration = 34\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteration = 35\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteration = 36\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteration = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "                        pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                        metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:13.230517Z",
     "start_time": "2023-09-21T18:05:53.945101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features      10.000000\nn_estimators    1000.000000\nmax_samples     1000.000000\nmetric_train       0.962544\nmetric_val         0.937265\nName: 35, dtype: float64"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:13.236311Z",
     "start_time": "2023-09-21T18:07:13.232497Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "model = model_constructor(max_features=int(best_model['max_features']),\n",
    "                          n_estimators=int(best_model['n_estimators']),\n",
    "                          max_samples=int(best_model['max_samples']),\n",
    "                          random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:13.240146Z",
     "start_time": "2023-09-21T18:07:13.238589Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "                   var       imp\n1      mortality_ratio  0.329915\n2                  age  0.233788\n3      expected_length  0.148166\n0             num_proc  0.121442\n21     tip_grd_UNKNOWN  0.027640\n18      origin_UNKNOWN  0.027140\n6         severity_4.0  0.023575\n25     tip_adm_UNKNOWN  0.019058\n7     severity_UNKNOWN  0.017575\n5         severity_3.0  0.016779\n10  ambulatory_UNKNOWN  0.010044\n4         severity_2.0  0.006798\n20           tip_grd_Q  0.006670\n23         tip_adm_2.0  0.005019\n24         tip_adm_3.0  0.002396\n15          origin_6.0  0.001718\n14          origin_4.0  0.000775\n12          origin_2.0  0.000731\n17          origin_9.0  0.000453\n13          origin_3.0  0.000284\n9       ambulatory_1.0  0.000017\n16          origin_8.0  0.000016\n19          origin_nan  0.000000\n22         tip_grd_nan  0.000000\n11      ambulatory_nan  0.000000\n8         severity_nan  0.000000\n26         tip_adm_nan  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>imp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>mortality_ratio</td>\n      <td>0.329915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>age</td>\n      <td>0.233788</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>expected_length</td>\n      <td>0.148166</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>num_proc</td>\n      <td>0.121442</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>tip_grd_UNKNOWN</td>\n      <td>0.027640</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>origin_UNKNOWN</td>\n      <td>0.027140</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>severity_4.0</td>\n      <td>0.023575</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>tip_adm_UNKNOWN</td>\n      <td>0.019058</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>severity_UNKNOWN</td>\n      <td>0.017575</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>severity_3.0</td>\n      <td>0.016779</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ambulatory_UNKNOWN</td>\n      <td>0.010044</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>severity_2.0</td>\n      <td>0.006798</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>tip_grd_Q</td>\n      <td>0.006670</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>tip_adm_2.0</td>\n      <td>0.005019</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>tip_adm_3.0</td>\n      <td>0.002396</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>origin_6.0</td>\n      <td>0.001718</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>origin_4.0</td>\n      <td>0.000775</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>origin_2.0</td>\n      <td>0.000731</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>origin_9.0</td>\n      <td>0.000453</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>origin_3.0</td>\n      <td>0.000284</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ambulatory_1.0</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>origin_8.0</td>\n      <td>0.000016</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>origin_nan</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>tip_grd_nan</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ambulatory_nan</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>severity_nan</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>tip_adm_nan</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "var_imp = pd.DataFrame({'var': dat.drop(['exitus', 'dataset'], axis = 1).columns, 'imp': model.feature_importances_})\n",
    "var_imp.sort_values(['imp'], ascending = False, inplace = True)\n",
    "var_imp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:15.624675Z",
     "start_time": "2023-09-21T18:07:13.243963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(max_features=10, max_samples=1000, n_estimators=1000,\n                       random_state=0)",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_features=10, max_samples=1000, n_estimators=1000,\n                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_features=10, max_samples=1000, n_estimators=1000,\n                       random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:18.030633Z",
     "start_time": "2023-09-21T18:07:15.628162Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mortality_ratio', 'age', 'expected_length', 'num_proc', 'tip_grd_UNKNOWN', 'origin_UNKNOWN', 'severity_4.0', 'tip_adm_UNKNOWN', 'severity_UNKNOWN', 'severity_3.0']\n"
     ]
    }
   ],
   "source": [
    "print(var_imp.nlargest(10, 'imp')['var'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:18.035870Z",
     "start_time": "2023-09-21T18:07:18.033470Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "dat = dat[['mortality_ratio', 'age', 'expected_length', 'num_proc', 'tip_grd_UNKNOWN', 'origin_UNKNOWN', 'severity_4.0', 'tip_adm_UNKNOWN', 'severity_UNKNOWN', 'severity_3.0', 'exitus', 'dataset']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:18.040197Z",
     "start_time": "2023-09-21T18:07:18.038810Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:22.123463Z",
     "start_time": "2023-09-21T18:07:18.044782Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {
    "id": "eAe2bKe7hK_c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# print error\n",
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-EPli1DiYGX",
    "outputId": "8e007bc0-142b-424d-ea6c-bfdaae328444",
    "ExecuteTime": {
     "end_time": "2023-09-21T18:07:22.127285Z",
     "start_time": "2023-09-21T18:07:22.124385Z"
    }
   },
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.96 - Metric val = 0.94 - Metric test = 0.94\n"
     ]
    }
   ]
  }
 ]
}
