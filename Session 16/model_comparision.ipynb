{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:43.236137Z",
     "start_time": "2023-10-08T19:57:35.504521600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../data/dataset_mock_midterm.csv', sep = \",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:45.297002Z",
     "start_time": "2023-10-08T19:57:45.169206500Z"
    }
   },
   "id": "c491374bb21a305f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "          date  severity  mortality_ratio      age  num_proc  ambulatory  \\\n0      2016-01       NaN         0.408730  12596.0      21.0         0.0   \n1      2016-01       NaN         0.306931  20973.0      22.0         NaN   \n2      2016-01       4.0         0.278481  19611.0      19.0         NaN   \n3      2016-01       3.0         0.150289  13583.0      22.0         NaN   \n4      2016-01       1.0         0.016573  18042.0       2.0         NaN   \n...        ...       ...              ...      ...       ...         ...   \n32701  2016-12       2.0         0.028365  23619.0       2.0         NaN   \n32702  2016-12       1.0         0.000606   3935.0       1.0         NaN   \n32703  2016-12       NaN         0.040452  30163.0       4.0         NaN   \n32704  2016-12       NaN         0.000000  29012.0       4.0         NaN   \n32705  2016-12       NaN         0.000000  13244.0       1.0         NaN   \n\n       origin  expected_length tip_grd  tip_adm  exitus dataset  \n0         NaN            151.0       Q      1.0       0   train  \n1         NaN             99.0       Q      1.0       0   train  \n2         NaN             87.0     NaN      1.0       0   train  \n3         NaN            100.0       Q      NaN       0   train  \n4         NaN             44.0       Q      1.0       0   train  \n...       ...              ...     ...      ...     ...     ...  \n32701     NaN              2.0     NaN      1.0       0    test  \n32702     1.0              2.0       M      1.0       0    test  \n32703     NaN              2.0       M      NaN       0    test  \n32704     NaN              0.0     NaN      1.0       0    test  \n32705     NaN              0.0       Q      1.0       0    test  \n\n[32706 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.408730</td>\n      <td>12596.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>151.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.306931</td>\n      <td>20973.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>4.0</td>\n      <td>0.278481</td>\n      <td>19611.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>3.0</td>\n      <td>0.150289</td>\n      <td>13583.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.0</td>\n      <td>Q</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01</td>\n      <td>1.0</td>\n      <td>0.016573</td>\n      <td>18042.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>2016-12</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.040452</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:48:47.742842200Z",
     "start_time": "2023-09-29T13:48:47.706816500Z"
    }
   },
   "id": "48e440cbf290e985"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dat.drop('date', axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:47.394421Z",
     "start_time": "2023-10-08T19:57:47.330656900Z"
    }
   },
   "id": "24c865615d3a1b5d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "cat_var = ['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
    "non_cat_var = list(set(dat.columns) - set(cat_var))\n",
    "num_var = list(set(dat.columns) - set(cat_var) - {'dataset', 'exitus'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:48.421214400Z",
     "start_time": "2023-10-08T19:57:48.369316700Z"
    }
   },
   "id": "cc5760f4ad76c83d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio     True\nage                 True\nnum_proc            True\nambulatory          True\norigin              True\nexpected_length     True\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:49.137073200Z",
     "start_time": "2023-10-08T19:57:49.068137300Z"
    }
   },
   "id": "5752a0bae798680"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory          True\norigin              True\nexpected_length    False\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer as MICE\n",
    "# 3) Define \"model\"\n",
    "model = MICE()\n",
    "\n",
    "# 4) Train \"model\"\n",
    "model.fit(dat[num_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) \"Predict\"\n",
    "dat[num_var] = model.transform(dat[num_var])\n",
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:53.999080900Z",
     "start_time": "2023-10-08T19:57:51.072328200Z"
    }
   },
   "id": "de1fc953f880a583"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dat[cat_var] = dat[cat_var].astype('str')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:57:55.524116100Z",
     "start_time": "2023-10-08T19:57:55.417033400Z"
    }
   },
   "id": "dc7e861007859a6a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "severity      0\nambulatory    0\norigin        0\ntip_grd       0\ntip_adm       0\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.loc[dat['dataset'] == 'train', cat_var] = dat.loc[dat['dataset'] == 'train', cat_var].fillna('UNKNOWN')\n",
    "dat[cat_var][dat['dataset'] == 'train'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:10.132140400Z",
     "start_time": "2023-10-08T19:58:10.053456800Z"
    }
   },
   "id": "c50d041a2da326d"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "severity           False\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory         False\norigin             False\nexpected_length    False\ntip_grd            False\ntip_adm            False\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:12.106081800Z",
     "start_time": "2023-10-08T19:58:12.052835800Z"
    }
   },
   "id": "66f69e38ac9bfc1a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False, drop='first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(dat[cat_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(dat[cat_var]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "dat = pd.concat((dat[non_cat_var], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:14.097974400Z",
     "start_time": "2023-10-08T19:58:14.004236700Z"
    }
   },
   "id": "4c5ed9b9152fb0f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1 Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc6d585039c438f"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as model_constructor_1\n",
    "from sklearn.metrics import roc_auc_score as metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:16.284951100Z",
     "start_time": "2023-10-08T19:58:16.202290500Z"
    }
   },
   "id": "afe9f1d1adaf586f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "criterion_values = ['gini', 'entropy']\n",
    "max_depth_values = [5, 6, 7]\n",
    "min_samples_split_values = [10, 20, 30]\n",
    "min_samples_leaf_values = [29, 30, 31]\n",
    "max_features_values = [None, 1, 2]\n",
    "\n",
    "params_grid = {  'criterion': criterion_values,\n",
    "                 'max_depth': max_depth_values,\n",
    "                 'min_samples_split': min_samples_split_values,\n",
    "                 'min_samples_leaf': min_samples_leaf_values,\n",
    "                 'max_features': max_features_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:19.158569100Z",
     "start_time": "2023-10-08T19:58:19.106932600Z"
    }
   },
   "id": "587950ec09aba8e2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 iterations of Decision Tree\n"
     ]
    }
   ],
   "source": [
    "n = len(params_grid['max_depth'])*len(params_grid['min_samples_split'])*len(params_grid['min_samples_leaf'])*len(params_grid['max_features'])*len(params_grid['criterion'])\n",
    "print(str(n)+ ' iterations of Decision Tree')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:20.926955100Z",
     "start_time": "2023-10-08T19:58:20.887951600Z"
    }
   },
   "id": "d60199ee2d3354e9"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.26.\n",
      "Iteracion = 2\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 3\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 4\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 5\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 6\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.05.\n",
      "Iteracion = 7\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 8\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 9\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 10\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 11\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 12\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 13\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 14\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 15\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 16\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 17\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 18\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 19\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 20\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 21\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 22\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 23\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 24\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 25\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 26\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 27\n",
      "AUC train = 0.79 - AUC validation = 0.75. Time spend = 0.04.\n",
      "Iteracion = 28\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 29\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 30\n",
      "AUC train = 0.88 - AUC validation = 0.83. Time spend = 0.04.\n",
      "Iteracion = 31\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.10.\n",
      "Iteracion = 32\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 33\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 34\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 35\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.05.\n",
      "Iteracion = 36\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 37\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 38\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 39\n",
      "AUC train = 0.88 - AUC validation = 0.83. Time spend = 0.04.\n",
      "Iteracion = 40\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 41\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.05.\n",
      "Iteracion = 42\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.06.\n",
      "Iteracion = 43\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 44\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 45\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 46\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.11.\n",
      "Iteracion = 47\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.05.\n",
      "Iteracion = 48\n",
      "AUC train = 0.88 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 49\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 50\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.05.\n",
      "Iteracion = 51\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 52\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 53\n",
      "AUC train = 0.79 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 54\n",
      "AUC train = 0.87 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 55\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 56\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 57\n",
      "AUC train = 0.86 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 58\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 59\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 60\n",
      "AUC train = 0.89 - AUC validation = 0.86. Time spend = 0.05.\n",
      "Iteracion = 61\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 62\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 63\n",
      "AUC train = 0.88 - AUC validation = 0.85. Time spend = 0.05.\n",
      "Iteracion = 64\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 65\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 66\n",
      "AUC train = 0.86 - AUC validation = 0.83. Time spend = 0.04.\n",
      "Iteracion = 67\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 68\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 69\n",
      "AUC train = 0.89 - AUC validation = 0.86. Time spend = 0.05.\n",
      "Iteracion = 70\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 71\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 72\n",
      "AUC train = 0.88 - AUC validation = 0.85. Time spend = 0.04.\n",
      "Iteracion = 73\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 74\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 75\n",
      "AUC train = 0.86 - AUC validation = 0.83. Time spend = 0.05.\n",
      "Iteracion = 76\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 77\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 78\n",
      "AUC train = 0.89 - AUC validation = 0.86. Time spend = 0.04.\n",
      "Iteracion = 79\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 80\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 81\n",
      "AUC train = 0.88 - AUC validation = 0.85. Time spend = 0.04.\n",
      "Iteracion = 82\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 83\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 84\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 85\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 86\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 87\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 88\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 89\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 90\n",
      "AUC train = 0.80 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 91\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 92\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 93\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 94\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 95\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 96\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 97\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 98\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 99\n",
      "AUC train = 0.80 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 100\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 101\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 102\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 103\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 104\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 105\n",
      "AUC train = 0.81 - AUC validation = 0.82. Time spend = 0.04.\n",
      "Iteracion = 106\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 107\n",
      "AUC train = 0.67 - AUC validation = 0.66. Time spend = 0.04.\n",
      "Iteracion = 108\n",
      "AUC train = 0.80 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 109\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 110\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 111\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 112\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 113\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 114\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 115\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 116\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 117\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 118\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 119\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 120\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 121\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 122\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 123\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 124\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 125\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 126\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 127\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 128\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 129\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 130\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 131\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 132\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 133\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 134\n",
      "AUC train = 0.80 - AUC validation = 0.77. Time spend = 0.04.\n",
      "Iteracion = 135\n",
      "AUC train = 0.89 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 136\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.09.\n",
      "Iteracion = 137\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 138\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 139\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 140\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 141\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 142\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 143\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 144\n",
      "AUC train = 0.83 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 145\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.09.\n",
      "Iteracion = 146\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 147\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 148\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 149\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 150\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 151\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 152\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 153\n",
      "AUC train = 0.83 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 154\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.09.\n",
      "Iteracion = 155\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 156\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 157\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 158\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 159\n",
      "AUC train = 0.84 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Iteracion = 160\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 161\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 162\n",
      "AUC train = 0.83 - AUC validation = 0.78. Time spend = 0.04.\n",
      "Grid Search Total Computational Time:  9.323009200000456\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('criterion',\n",
    "                                       'max_depth',\n",
    "                                       'min_samples_split',\n",
    "                                       'min_samples_leaf',\n",
    "                                       'max_features',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for criterion in params_grid['criterion']:\n",
    "    for max_depth in params_grid['max_depth']:\n",
    "        for min_samples_split in params_grid['min_samples_split']:\n",
    "            for min_samples_leaf in params_grid['min_samples_leaf']:\n",
    "                for max_features in params_grid['max_features']:\n",
    "\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_1(criterion = criterion,\n",
    "                                              max_depth = max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf,\n",
    "                                              max_features = max_features,\n",
    "                                              random_state = 0)\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Evaluate\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[criterion,\n",
    "                                                max_depth,\n",
    "                                                min_samples_split,\n",
    "                                                min_samples_leaf,\n",
    "                                                max_features,\n",
    "                                             metric_train,\n",
    "                                             metric_val,\n",
    "                                            time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T19:58:32.585114200Z",
     "start_time": "2023-10-08T19:58:23.085060500Z"
    }
   },
   "id": "a4d00e09cc98d9db"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n40      gini          6                 20                30         None   \n49      gini          6                 30                30         None   \n31      gini          6                 10                30         None   \n34      gini          6                 10                31         None   \n43      gini          6                 20                31         None   \n..       ...        ...                ...               ...          ...   \n8       gini          5                 10                31            1   \n20      gini          5                 30                29            1   \n14      gini          5                 20                30            1   \n5       gini          5                 10                30            1   \n17      gini          5                 20                31            1   \n\n    auc_train   auc_val      time  \n40   0.946581  0.935483  0.087221  \n49   0.946581  0.935483  0.087869  \n31   0.946581  0.935483  0.099775  \n34   0.946536  0.935474  0.089911  \n43   0.946536  0.935474  0.089917  \n..        ...       ...       ...  \n8    0.669191  0.656327  0.040343  \n20   0.669191  0.656327  0.040515  \n14   0.669191  0.656327  0.041375  \n5    0.669191  0.656327  0.041552  \n17   0.669191  0.656327  0.041620  \n\n[162 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>criterion</th>\n      <th>max_depth</th>\n      <th>min_samples_split</th>\n      <th>min_samples_leaf</th>\n      <th>max_features</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>40</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935483</td>\n      <td>0.087221</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935483</td>\n      <td>0.087869</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935483</td>\n      <td>0.099775</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.089911</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.089917</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>gini</td>\n      <td>5</td>\n      <td>10</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.669191</td>\n      <td>0.656327</td>\n      <td>0.040343</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>gini</td>\n      <td>5</td>\n      <td>30</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0.669191</td>\n      <td>0.656327</td>\n      <td>0.040515</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>gini</td>\n      <td>5</td>\n      <td>20</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.669191</td>\n      <td>0.656327</td>\n      <td>0.041375</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>gini</td>\n      <td>5</td>\n      <td>10</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.669191</td>\n      <td>0.656327</td>\n      <td>0.041552</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>gini</td>\n      <td>5</td>\n      <td>20</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.669191</td>\n      <td>0.656327</td>\n      <td>0.041620</td>\n    </tr>\n  </tbody>\n</table>\n<p>162 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:01:36.662258400Z",
     "start_time": "2023-10-08T20:01:36.554855600Z"
    }
   },
   "id": "27fa74f69d18afb0"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "criterion                gini\nmax_depth                   6\nmin_samples_split          20\nmin_samples_leaf           30\nmax_features             None\nauc_train            0.946581\nauc_val              0.935483\ntime                 0.087221\nName: 40, dtype: object"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:01:52.162671Z",
     "start_time": "2023-10-08T20:01:52.134072500Z"
    }
   },
   "id": "c0e9831c027d57e8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model  = model_constructor_1(criterion = best_model['criterion'],\n",
    "                                              max_depth = best_model['max_depth'],\n",
    "                                              min_samples_split = best_model['min_samples_split'],\n",
    "                                              min_samples_leaf = best_model['min_samples_leaf'],\n",
    "                                              max_features = best_model['max_features'],\n",
    "                                              random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:01:59.937846600Z",
     "start_time": "2023-10-08T20:01:59.916222900Z"
    }
   },
   "id": "4cff231d011f886d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:00.978656100Z",
     "start_time": "2023-10-08T20:02:00.896361800Z"
    }
   },
   "id": "56da93d4a4612391"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:03.072915800Z",
     "start_time": "2023-10-08T20:02:02.987598900Z"
    }
   },
   "id": "9f95ffa26429c2db"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.95 - Metric val = 0.94 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:05.116126600Z",
     "start_time": "2023-10-08T20:02:05.088738900Z"
    }
   },
   "id": "b35cdf2c78ff3a5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying Oversampling and Subsampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c488699bc4716e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       96.159726\n1        3.840274",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96.159726</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.840274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*dat.groupby(['exitus'])['exitus'].agg(['count'])/dat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:10.207649800Z",
     "start_time": "2023-10-08T20:02:10.116385Z"
    }
   },
   "id": "5ed40644a1df459d"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = dat[dat['dataset'] == 'train']\n",
    "test_data = dat[dat['dataset'] == 'test']\n",
    "val_data = dat[dat['dataset'] == 'val']\n",
    "\n",
    "# Determine the minority class in the training data\n",
    "minority_class_len = min(train_data['exitus'].value_counts().tolist())\n",
    "\n",
    "# Subsample the majority class in the training data\n",
    "majority_class_indices = train_data[train_data['exitus'] == 0].index\n",
    "random_major_indices = np.random.choice(majority_class_indices, minority_class_len, replace=False)\n",
    "random_major_indices = np.array(random_major_indices)\n",
    "\n",
    "# Get the indices of the minority class in the training data\n",
    "minority_class_indices = train_data[train_data['exitus'] == 1].index\n",
    "\n",
    "# Concatenate the indices to create a balanced training dataset\n",
    "under_sample_indices = np.concatenate([minority_class_indices, random_major_indices])\n",
    "under_sample_train_data = train_data.loc[under_sample_indices]\n",
    "\n",
    "# Now, let's concatenate train, validation, and test to create data_new\n",
    "data_new = pd.concat([under_sample_train_data, val_data, test_data], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:16.575227100Z",
     "start_time": "2023-10-08T20:02:16.550158600Z"
    }
   },
   "id": "2c2e2da998ea5ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "       exitus  expected_length  mortality_ratio dataset      age  num_proc  \\\n7           1             40.0         0.074278   train  21685.0       7.0   \n10          1             31.0         0.484536   train  31612.0       9.0   \n13          1             14.0         0.231884   train  24755.0      14.0   \n40          1             31.0         0.250000   train  17226.0      19.0   \n42          1             10.0         0.090515   train  28992.0       9.0   \n...       ...              ...              ...     ...      ...       ...   \n32701       0              2.0         0.028365    test  23619.0       2.0   \n32702       0              2.0         0.000606    test   3935.0       1.0   \n32703       0              2.0         0.040452    test  30163.0       4.0   \n32704       0              0.0         0.000000    test  29012.0       4.0   \n32705       0              0.0         0.000000    test  13244.0       1.0   \n\n       severity_2.0  severity_3.0  severity_4.0  severity_nan  ...  \\\n7               0.0           1.0           0.0           0.0  ...   \n10              0.0           0.0           1.0           0.0  ...   \n13              0.0           0.0           0.0           1.0  ...   \n40              0.0           0.0           0.0           1.0  ...   \n42              0.0           0.0           0.0           1.0  ...   \n...             ...           ...           ...           ...  ...   \n32701           1.0           0.0           0.0           0.0  ...   \n32702           0.0           0.0           0.0           0.0  ...   \n32703           0.0           0.0           0.0           1.0  ...   \n32704           0.0           0.0           0.0           1.0  ...   \n32705           0.0           0.0           0.0           1.0  ...   \n\n       origin_4.0  origin_6.0  origin_8.0  origin_9.0  origin_nan  tip_grd_Q  \\\n7             0.0         0.0         0.0         0.0         1.0        0.0   \n10            0.0         0.0         0.0         0.0         1.0        0.0   \n13            0.0         0.0         0.0         0.0         1.0        0.0   \n40            0.0         0.0         0.0         0.0         0.0        0.0   \n42            0.0         0.0         0.0         0.0         0.0        0.0   \n...           ...         ...         ...         ...         ...        ...   \n32701         0.0         0.0         0.0         0.0         1.0        0.0   \n32702         0.0         0.0         0.0         0.0         0.0        0.0   \n32703         0.0         0.0         0.0         0.0         1.0        0.0   \n32704         0.0         0.0         0.0         0.0         1.0        0.0   \n32705         0.0         0.0         0.0         0.0         1.0        1.0   \n\n       tip_grd_nan  tip_adm_2.0  tip_adm_3.0  tip_adm_nan  \n7              1.0          0.0          0.0          1.0  \n10             0.0          0.0          0.0          0.0  \n13             0.0          0.0          0.0          0.0  \n40             0.0          0.0          0.0          1.0  \n42             0.0          0.0          0.0          0.0  \n...            ...          ...          ...          ...  \n32701          1.0          0.0          0.0          0.0  \n32702          0.0          0.0          0.0          0.0  \n32703          0.0          0.0          0.0          1.0  \n32704          1.0          0.0          0.0          0.0  \n32705          0.0          0.0          0.0          0.0  \n\n[11582 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exitus</th>\n      <th>expected_length</th>\n      <th>mortality_ratio</th>\n      <th>dataset</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>severity_2.0</th>\n      <th>severity_3.0</th>\n      <th>severity_4.0</th>\n      <th>severity_nan</th>\n      <th>...</th>\n      <th>origin_4.0</th>\n      <th>origin_6.0</th>\n      <th>origin_8.0</th>\n      <th>origin_9.0</th>\n      <th>origin_nan</th>\n      <th>tip_grd_Q</th>\n      <th>tip_grd_nan</th>\n      <th>tip_adm_2.0</th>\n      <th>tip_adm_3.0</th>\n      <th>tip_adm_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>40.0</td>\n      <td>0.074278</td>\n      <td>train</td>\n      <td>21685.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>31.0</td>\n      <td>0.484536</td>\n      <td>train</td>\n      <td>31612.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>14.0</td>\n      <td>0.231884</td>\n      <td>train</td>\n      <td>24755.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1</td>\n      <td>31.0</td>\n      <td>0.250000</td>\n      <td>train</td>\n      <td>17226.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>0.090515</td>\n      <td>train</td>\n      <td>28992.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>test</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.000606</td>\n      <td>test</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.040452</td>\n      <td>test</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>test</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>test</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11582 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:33.995520700Z",
     "start_time": "2023-10-04T14:57:33.951294900Z"
    }
   },
   "id": "c226dd268f56cffa"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       89.155586\n1       10.844414",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>89.155586</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.844414</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*data_new.groupby(['exitus'])['exitus'].agg(['count'])/data_new.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:02:19.213716300Z",
     "start_time": "2023-10-08T20:02:19.188360Z"
    }
   },
   "id": "276d73aeffdc65c3"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a 20.0% minority class after oversampling, set sampling_strategy to 0.25 in SMOTE.\n"
     ]
    }
   ],
   "source": [
    "def compute_sampling_strategy(frac_minority, minority_count, majority_count):\n",
    "    synthetic_samples = (frac_minority * majority_count - (1 - frac_minority) * minority_count) / (1 - frac_minority)\n",
    "    strategy = (minority_count + synthetic_samples) / majority_count\n",
    "    return strategy\n",
    "\n",
    "# Assume you have counts for your classes\n",
    "minority_count = sum(dat['exitus'] == 1)\n",
    "majority_count = sum(dat['exitus'] == 0)\n",
    "\n",
    "# For a 10-90 split:\n",
    "fraction = 0.2\n",
    "sampling_value = compute_sampling_strategy(fraction, minority_count, majority_count)\n",
    "print(f\"For a {fraction*100}% minority class after oversampling, set sampling_strategy to {sampling_value:.2f} in SMOTE.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:03:01.603646200Z",
     "start_time": "2023-10-08T20:03:01.578203400Z"
    }
   },
   "id": "b48430f007662e80"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "exitus\n0    80.001018\n1    19.998982\nName: count, dtype: float64"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy =sampling_value,\n",
    "           random_state = 0,\n",
    "           k_neighbors = 5)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(dat.drop(['exitus', 'dataset'], axis = 1), dat['exitus'])\n",
    "\n",
    "X_res['exitus'] = y_res\n",
    "\n",
    "X_res['dataset'] = 'train'\n",
    "\n",
    "dat = pd.concat([X_res, dat[dat['dataset'] == 'val'], dat[dat['dataset'] == 'test']])\n",
    "\n",
    "# Checking the class distribution after SMOTE\n",
    "100*X_res.exitus.value_counts()/X_res.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:04:42.153572Z",
     "start_time": "2023-10-08T20:04:42.032974500Z"
    }
   },
   "id": "464c8e71906a2d77"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "criterion_values = ['gini', 'entropy']\n",
    "max_depth_values = [5, 6, 7]\n",
    "min_samples_split_values = [10, 20, 30]\n",
    "min_samples_leaf_values = [29, 30, 31]\n",
    "max_features_values = [None, 1, 2]\n",
    "\n",
    "params_grid = {  'criterion': criterion_values,\n",
    "                 'max_depth': max_depth_values,\n",
    "                 'min_samples_split': min_samples_split_values,\n",
    "                 'min_samples_leaf': min_samples_leaf_values,\n",
    "                 'max_features': max_features_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:04:45.519670700Z",
     "start_time": "2023-10-08T20:04:45.490536700Z"
    }
   },
   "id": "a81c3d99895caf0e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.18.\n",
      "Iteracion = 2\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 3\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.09.\n",
      "Iteracion = 4\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.18.\n",
      "Iteracion = 5\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 6\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.10.\n",
      "Iteracion = 7\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.18.\n",
      "Iteracion = 8\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 9\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.09.\n",
      "Iteracion = 10\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.18.\n",
      "Iteracion = 11\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 12\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.09.\n",
      "Iteracion = 13\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.21.\n",
      "Iteracion = 14\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 15\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.10.\n",
      "Iteracion = 16\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.19.\n",
      "Iteracion = 17\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 18\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.09.\n",
      "Iteracion = 19\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.20.\n",
      "Iteracion = 20\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 21\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.09.\n",
      "Iteracion = 22\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.20.\n",
      "Iteracion = 23\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.08.\n",
      "Iteracion = 24\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.09.\n",
      "Iteracion = 25\n",
      "AUC train = 0.97 - AUC validation = 0.92. Time spend = 0.19.\n",
      "Iteracion = 26\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 27\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 28\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 29\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 30\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.09.\n",
      "Iteracion = 31\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 32\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 33\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.09.\n",
      "Iteracion = 34\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 35\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 36\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.08.\n",
      "Iteracion = 37\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 38\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 39\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.08.\n",
      "Iteracion = 40\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 41\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 42\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.09.\n",
      "Iteracion = 43\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 44\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 45\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.08.\n",
      "Iteracion = 46\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 47\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 48\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.09.\n",
      "Iteracion = 49\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.26.\n",
      "Iteracion = 50\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 51\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.11.\n",
      "Iteracion = 52\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.24.\n",
      "Iteracion = 53\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 54\n",
      "AUC train = 0.92 - AUC validation = 0.84. Time spend = 0.14.\n",
      "Iteracion = 55\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 56\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 57\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 58\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 59\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 60\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 61\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 62\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 63\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 64\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 65\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.09.\n",
      "Iteracion = 66\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.09.\n",
      "Iteracion = 67\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 68\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 69\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.13.\n",
      "Iteracion = 70\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 71\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.08.\n",
      "Iteracion = 72\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 73\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 74\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 75\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 76\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 77\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 78\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 79\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 80\n",
      "AUC train = 0.71 - AUC validation = 0.67. Time spend = 0.07.\n",
      "Iteracion = 81\n",
      "AUC train = 0.83 - AUC validation = 0.77. Time spend = 0.08.\n",
      "Iteracion = 82\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 83\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 84\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.08.\n",
      "Iteracion = 85\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 86\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 87\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 88\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 89\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 90\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 91\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.18.\n",
      "Iteracion = 92\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 93\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.08.\n",
      "Iteracion = 94\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.18.\n",
      "Iteracion = 95\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 96\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 97\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.18.\n",
      "Iteracion = 98\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 99\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 100\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 101\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 102\n",
      "AUC train = 0.91 - AUC validation = 0.81. Time spend = 0.09.\n",
      "Iteracion = 103\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.19.\n",
      "Iteracion = 104\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 105\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 106\n",
      "AUC train = 0.97 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 107\n",
      "AUC train = 0.74 - AUC validation = 0.62. Time spend = 0.07.\n",
      "Iteracion = 108\n",
      "AUC train = 0.93 - AUC validation = 0.85. Time spend = 0.08.\n",
      "Iteracion = 109\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.23.\n",
      "Iteracion = 110\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 111\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.10.\n",
      "Iteracion = 112\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.23.\n",
      "Iteracion = 113\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 114\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.10.\n",
      "Iteracion = 115\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 116\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 117\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.09.\n",
      "Iteracion = 118\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.24.\n",
      "Iteracion = 119\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 120\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.12.\n",
      "Iteracion = 121\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 122\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 123\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.09.\n",
      "Iteracion = 124\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 125\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 126\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.15.\n",
      "Iteracion = 127\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 128\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.08.\n",
      "Iteracion = 129\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.08.\n",
      "Iteracion = 130\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.18.\n",
      "Iteracion = 131\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 132\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.08.\n",
      "Iteracion = 133\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.19.\n",
      "Iteracion = 134\n",
      "AUC train = 0.70 - AUC validation = 0.61. Time spend = 0.07.\n",
      "Iteracion = 135\n",
      "AUC train = 0.90 - AUC validation = 0.82. Time spend = 0.08.\n",
      "Iteracion = 136\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 137\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.08.\n",
      "Iteracion = 138\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.08.\n",
      "Iteracion = 139\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 140\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 141\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.09.\n",
      "Iteracion = 142\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.24.\n",
      "Iteracion = 143\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 144\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.10.\n",
      "Iteracion = 145\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.23.\n",
      "Iteracion = 146\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 147\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.12.\n",
      "Iteracion = 148\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 149\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 150\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.17.\n",
      "Iteracion = 151\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 152\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.08.\n",
      "Iteracion = 153\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.09.\n",
      "Iteracion = 154\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.20.\n",
      "Iteracion = 155\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.08.\n",
      "Iteracion = 156\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.10.\n",
      "Iteracion = 157\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.22.\n",
      "Iteracion = 158\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 159\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.10.\n",
      "Iteracion = 160\n",
      "AUC train = 0.98 - AUC validation = 0.93. Time spend = 0.21.\n",
      "Iteracion = 161\n",
      "AUC train = 0.70 - AUC validation = 0.68. Time spend = 0.07.\n",
      "Iteracion = 162\n",
      "AUC train = 0.87 - AUC validation = 0.79. Time spend = 0.10.\n",
      "Grid Search Total Computational Time:  20.331392800002277\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('criterion',\n",
    "                                       'max_depth',\n",
    "                                       'min_samples_split',\n",
    "                                       'min_samples_leaf',\n",
    "                                       'max_features',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for criterion in params_grid['criterion']:\n",
    "    for max_depth in params_grid['max_depth']:\n",
    "        for min_samples_split in params_grid['min_samples_split']:\n",
    "            for min_samples_leaf in params_grid['min_samples_leaf']:\n",
    "                for max_features in params_grid['max_features']:\n",
    "\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_1(criterion = criterion,\n",
    "                                              max_depth = max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf,\n",
    "                                              max_features = max_features,\n",
    "                                              random_state = 0)\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Evaluate\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[criterion,\n",
    "                                                max_depth,\n",
    "                                                min_samples_split,\n",
    "                                                min_samples_leaf,\n",
    "                                                max_features,\n",
    "                                             metric_train,\n",
    "                                             metric_val,\n",
    "                                            time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:07.351542800Z",
     "start_time": "2023-10-08T20:04:46.850517700Z"
    }
   },
   "id": "be2af55cc1194c0e"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'auc_val'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_18236\\2616064217.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mgrid_results\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgrid_results\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mby\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;34m'auc_val'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'auc_train'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'time'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mascending\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mgrid_results\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001B[0m\n\u001B[0;32m   6926\u001B[0m                 \u001B[1;34mf\"Length of ascending ({len(ascending)})\"\u001B[0m  \u001B[1;31m# type: ignore[arg-type]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6927\u001B[0m                 \u001B[1;34mf\" != length of by ({len(by)})\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6928\u001B[0m             )\n\u001B[0;32m   6929\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mby\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 6930\u001B[1;33m             \u001B[0mkeys\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_label_or_level_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mby\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   6931\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6932\u001B[0m             \u001B[1;31m# need to rewrap columns in Series to apply key function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   6933\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(.0)\u001B[0m\n\u001B[1;32m-> 6930\u001B[1;33m         \u001B[1;33m...\u001B[0m     \u001B[0mkey\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindex_natsorted\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"time\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1840\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mxs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mother_axes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1841\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_level_reference\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1842\u001B[0m             \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0maxes\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_level_values\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1843\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1844\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1845\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1846\u001B[0m         \u001B[1;31m# Check for duplicates\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1847\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'auc_val'"
     ]
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:09:24.883408600Z",
     "start_time": "2023-10-08T20:09:24.409776Z"
    }
   },
   "id": "bc7069a545c889ea"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "criterion             entropy\nmax_depth                   7\nmin_samples_split          30\nmin_samples_leaf           31\nmax_features             None\nauc_train            0.979683\nauc_val              0.934562\ntime                  0.21484\nName: 160, dtype: object"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:12.356786700Z",
     "start_time": "2023-10-08T20:05:12.334528Z"
    }
   },
   "id": "643f7944c413536b"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "model  = model_constructor_1(criterion = best_model['criterion'],\n",
    "                                              max_depth = best_model['max_depth'],\n",
    "                                              min_samples_split = best_model['min_samples_split'],\n",
    "                                              min_samples_leaf = best_model['min_samples_leaf'],\n",
    "                                              max_features = best_model['max_features'],\n",
    "                                              random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:14.302732100Z",
     "start_time": "2023-10-08T20:05:14.268849300Z"
    }
   },
   "id": "df34881762d8f3fd"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(criterion='entropy', max_depth=7, min_samples_leaf=31,\n                       min_samples_split=30, random_state=0)",
      "text/html": "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=7, min_samples_leaf=31,\n                       min_samples_split=30, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=7, min_samples_leaf=31,\n                       min_samples_split=30, random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:15.658759100Z",
     "start_time": "2023-10-08T20:05:15.493813100Z"
    }
   },
   "id": "521039837f9fac86"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:17.667591900Z",
     "start_time": "2023-10-08T20:05:17.541973Z"
    }
   },
   "id": "2ca39057c329008c"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.98 - Metric val = 0.93 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:20.357489100Z",
     "start_time": "2023-10-08T20:05:20.333502400Z"
    }
   },
   "id": "367edddccee39036"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61c89d20a9dd4de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 2 Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c3bc82b733bc28a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:31.627899900Z",
     "start_time": "2023-10-08T20:05:31.607640600Z"
    }
   },
   "id": "d87263ca05fa8b7e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_estimators_values = [10, 100, 1000]\n",
    "max_features_values = [2, 5, 10]\n",
    "max_samples_values = [100, 1000, dat[dat['dataset'] == 'train'].shape[0]]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:05:32.548432Z",
     "start_time": "2023-10-08T20:05:32.519176700Z"
    }
   },
   "id": "ddeec08166838024"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.95 - Metric validation = 0.89.\n",
      "Iteracion = 2\n",
      "Metric train = 0.98 - Metric validation = 0.90.\n",
      "Iteracion = 3\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 4\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 5\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 6\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 7\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 8\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 9\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 10\n",
      "Metric train = 0.95 - Metric validation = 0.90.\n",
      "Iteracion = 11\n",
      "Metric train = 0.97 - Metric validation = 0.90.\n",
      "Iteracion = 12\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 13\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 14\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 15\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 16\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 17\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 18\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 19\n",
      "Metric train = 0.95 - Metric validation = 0.90.\n",
      "Iteracion = 20\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 21\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 22\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 23\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 24\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 25\n",
      "Metric train = 0.97 - Metric validation = 0.93.\n",
      "Iteracion = 26\n",
      "Metric train = 0.99 - Metric validation = 0.95.\n",
      "Iteracion = 27\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor_2(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "                        pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                        metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:09:24.409776Z",
     "start_time": "2023-10-08T20:05:34.540104700Z"
    }
   },
   "id": "9883eb3ff1deee2e"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features        2.0\nn_estimators      100.0\nmax_samples     39312.0\nmetric_train        1.0\nmetric_val          1.0\nName: 6, dtype: float64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:16:53.388824600Z",
     "start_time": "2023-10-08T20:16:53.368801400Z"
    }
   },
   "id": "116791af06edcb42"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "                var       imp\n2   mortality_ratio  0.049664\n0               age  0.029276\n3   expected_length  0.026952\n6      severity_4.0  0.017411\n1          num_proc  0.017166\n18      tip_grd_nan  0.015617\n16       origin_nan  0.014475\n21      tip_adm_nan  0.007788\n7      severity_nan  0.006932\n5      severity_3.0  0.003262\n4      severity_2.0  0.001509\n9    ambulatory_nan  0.000734\n20      tip_adm_3.0  0.000408\n17        tip_grd_Q  0.000285\n19      tip_adm_2.0  0.000122\n8    ambulatory_1.0  0.000000\n10       origin_2.0  0.000000\n12       origin_4.0  0.000000\n13       origin_6.0  0.000000\n14       origin_8.0  0.000000\n15       origin_9.0  0.000000\n11       origin_3.0  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>imp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>mortality_ratio</td>\n      <td>0.049664</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>0.029276</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>expected_length</td>\n      <td>0.026952</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>severity_4.0</td>\n      <td>0.017411</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>num_proc</td>\n      <td>0.017166</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tip_grd_nan</td>\n      <td>0.015617</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>origin_nan</td>\n      <td>0.014475</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>tip_adm_nan</td>\n      <td>0.007788</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>severity_nan</td>\n      <td>0.006932</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>severity_3.0</td>\n      <td>0.003262</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>severity_2.0</td>\n      <td>0.001509</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ambulatory_nan</td>\n      <td>0.000734</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>tip_adm_3.0</td>\n      <td>0.000408</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>tip_grd_Q</td>\n      <td>0.000285</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tip_adm_2.0</td>\n      <td>0.000122</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ambulatory_1.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>origin_2.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>origin_4.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>origin_6.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>origin_8.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>origin_9.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>origin_3.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "res = permutation_importance(model,\n",
    "                       dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                       dat[dat['dataset'] == 'val'].exitus.values)\n",
    "var_imp = pd.DataFrame({'var': dat.drop(['exitus', 'dataset'], axis = 1).columns, 'imp': res['importances_mean']})\n",
    "var_imp.sort_values(['imp'], ascending = False, inplace = True)\n",
    "var_imp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T20:19:11.128900400Z",
     "start_time": "2023-10-08T20:18:16.317176700Z"
    }
   },
   "id": "e0f1d6ba24700f98"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "dat = dat[['mortality_ratio', 'age', 'expected_length', 'num_proc', 'exitus', 'dataset']] # This is just a fake example of how to select the most important variables."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:51:28.037961200Z",
     "start_time": "2023-09-29T13:51:28.032189500Z"
    }
   },
   "id": "553dff2f58aa3afd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.280773200Z",
     "start_time": "2023-09-29T13:51:28.039964200Z"
    }
   },
   "id": "b9645cf6d73b105c"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 1.00 - Metric val = 0.92 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "# print error\n",
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.287810100Z",
     "start_time": "2023-09-29T13:52:22.281774400Z"
    }
   },
   "id": "8443653ec903fb25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 3 XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91082899d3525ad3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as model_constructor_3\n",
    "\n",
    "model = model_constructor_3(early_stopping_rounds=10,\n",
    "                            n_estimators=1000,\n",
    "                            eval_metric=\"auc\",\n",
    "                            random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.350936800Z",
     "start_time": "2023-09-29T13:52:22.286812700Z"
    }
   },
   "id": "4994fea304b523d8"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.92578\n",
      "[1]\tvalidation_0-auc:0.92765\n",
      "[2]\tvalidation_0-auc:0.92970\n",
      "[3]\tvalidation_0-auc:0.93286\n",
      "[4]\tvalidation_0-auc:0.93248\n",
      "[5]\tvalidation_0-auc:0.93186\n",
      "[6]\tvalidation_0-auc:0.93142\n",
      "[7]\tvalidation_0-auc:0.93240\n",
      "[8]\tvalidation_0-auc:0.93261\n",
      "[9]\tvalidation_0-auc:0.93175\n",
      "[10]\tvalidation_0-auc:0.93247\n",
      "[11]\tvalidation_0-auc:0.93232\n",
      "[12]\tvalidation_0-auc:0.93241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "          np.array(dat[dat['dataset'] == 'train'].exitus.values),\n",
    "          eval_set=[(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'val'].exitus.values)], \n",
    "          verbose=True,\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.538109800Z",
     "start_time": "2023-09-29T13:52:22.336420500Z"
    }
   },
   "id": "5b6b770fbd8885e0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "               model  auc_train   auc_val  auc_test\n0  XGBoost (Default)   0.954507  0.932856  0.934233",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>auc_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost (Default)</td>\n      <td>0.954507</td>\n      <td>0.932856</td>\n      <td>0.934233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_p = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_val_p = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_test_p = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1))\n",
    "# Calcular métricas de evaluación\n",
    "auc_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train_p[:,1])\n",
    "auc_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val_p[:,1])\n",
    "auc_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test_p[:,1])\n",
    "results = pd.DataFrame()\n",
    "\n",
    "new_data = pd.DataFrame(data={'model': ['XGBoost (Default)'], 'auc_train': [auc_train], 'auc_val': [auc_val], 'auc_test': [auc_test]}, columns=['model', 'auc_train', 'auc_val', 'auc_test'])\n",
    "\n",
    "results = pd.concat([results, new_data], ignore_index=True)\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.557159200Z",
     "start_time": "2023-09-29T13:52:22.430246Z"
    }
   },
   "id": "101b847763be4c61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 4 SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d80eac6d1b84c35"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as model_constructor_4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.559157500Z",
     "start_time": "2023-09-29T13:52:22.473178700Z"
    }
   },
   "id": "2747fa5e7c129037"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "d = dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1).shape[1]\n",
    "m = np.mean(dat[dat['dataset'] == 'train'].exitus.values)\n",
    "s = np.std(dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.562664700Z",
     "start_time": "2023-09-29T13:52:22.476920100Z"
    }
   },
   "id": "441dbe1a1ab3d3d6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "C_cherk = np.max([np.abs(m + 3*s),np.abs(m - 3*s)])\n",
    "gamma_cherk = np.power(0.2, 1/d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.632191200Z",
     "start_time": "2023-09-29T13:52:22.501513100Z"
    }
   },
   "id": "21aad612055aad55"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# SVM\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 1, 100]\n",
    "\n",
    "params_grid = {'C': C_values,\n",
    "               'gamma': gamma_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.640715Z",
     "start_time": "2023-09-29T13:52:22.526083700Z"
    }
   },
   "id": "b8107d133f646f5b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "AUC train = 0.03 - AUC validation = 0.45. Time spend = 171.62.\n",
      "Iteracion = 2\n",
      "AUC train = 0.00 - AUC validation = 0.33. Time spend = 532.83.\n",
      "Iteracion = 3\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 594.49.\n",
      "Iteracion = 4\n",
      "AUC train = 0.03 - AUC validation = 0.45. Time spend = 300.82.\n",
      "Iteracion = 5\n",
      "AUC train = 0.00 - AUC validation = 0.32. Time spend = 714.31.\n",
      "Iteracion = 6\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 784.88.\n",
      "Iteracion = 7\n",
      "AUC train = 0.98 - AUC validation = 0.51. Time spend = 283.18.\n",
      "Iteracion = 8\n",
      "AUC train = 0.00 - AUC validation = 0.32. Time spend = 747.88.\n",
      "Iteracion = 9\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 757.84.\n",
      "Grid Search Total Computational Time:  4887.841272299993\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('C',\n",
    "                                       'gamma',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for C in params_grid['C']:\n",
    "    for gamma in params_grid['gamma']:\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_4(C = C,\n",
    "                                              gamma = gamma,\n",
    "                                              probability = True,\n",
    "                                              random_state = 0) # Probability = True!!!\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Compute metric\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,0])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,0])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[C,\n",
    "                                                gamma,\n",
    "                                                metric_train,\n",
    "                                                metric_val,\n",
    "                                                time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.475704400Z",
     "start_time": "2023-09-29T13:52:22.540109300Z"
    }
   },
   "id": "6e4502ed9fb8fe19"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "      C   gamma  auc_train   auc_val        time\n7  10.0    0.01   0.980731  0.508097  283.183016\n9  10.0  100.00   0.000000  0.488844  757.837903\n6   1.0  100.00   0.000000  0.488810  784.881326\n3   0.1  100.00   0.000000  0.488769  594.486062\n4   1.0    0.01   0.031175  0.453393  300.823236\n1   0.1    0.01   0.034346  0.452615  171.616194\n2   0.1    1.00   0.000000  0.326914  532.830954\n5   1.0    1.00   0.000000  0.324975  714.305631\n8  10.0    1.00   0.000000  0.324802  747.876950",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>gamma</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>10.0</td>\n      <td>0.01</td>\n      <td>0.980731</td>\n      <td>0.508097</td>\n      <td>283.183016</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.0</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488844</td>\n      <td>757.837903</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488810</td>\n      <td>784.881326</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.1</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488769</td>\n      <td>594.486062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.01</td>\n      <td>0.031175</td>\n      <td>0.453393</td>\n      <td>300.823236</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.1</td>\n      <td>0.01</td>\n      <td>0.034346</td>\n      <td>0.452615</td>\n      <td>171.616194</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.1</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.326914</td>\n      <td>532.830954</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.324975</td>\n      <td>714.305631</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10.0</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.324802</td>\n      <td>747.876950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.492099900Z",
     "start_time": "2023-09-29T15:13:50.477702200Z"
    }
   },
   "id": "cead764708e98a9d"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "C             10.000000\ngamma          0.010000\nauc_train      0.980731\nauc_val        0.508097\ntime         283.183016\nName: 7, dtype: float64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.506416200Z",
     "start_time": "2023-09-29T15:13:50.492099900Z"
    }
   },
   "id": "1d5370c40ced0dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old train data size = (22894, 4)\n",
      "Old train target size = (22894,)\n",
      "New train data size = (27799, 4)\n",
      "New train target size = (27799,)\n"
     ]
    }
   ],
   "source": [
    "print('Old train data size = ' + str(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1).shape))\n",
    "print('Old train target size = ' + str(dat[dat['dataset'] == 'train'].exitus.values.shape))\n",
    "\n",
    "# Combine train and validación\n",
    "X_train = np.concatenate((dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)), axis = 0)\n",
    "y_train = np.concatenate((dat[dat['dataset'] == 'train'].exitus.values, dat[dat['dataset'] == 'val'].exitus.values), axis = 0)\n",
    "\n",
    "print('New train data size = ' + str(X_train.shape))\n",
    "print('New train target size = ' + str(y_train.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.592511200Z",
     "start_time": "2023-09-29T15:13:50.507413900Z"
    }
   },
   "id": "4ad072ceeabca1cb"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (27799, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m pred_test \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexitus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# [6] Compute metric\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m metric_train \u001B[38;5;241m=\u001B[39m \u001B[43mmetric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43movo\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m metric_test \u001B[38;5;241m=\u001B[39m metric(dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mexitus\u001B[38;5;241m.\u001B[39mvalues, pred_test,multi_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:626\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    624\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n\u001B[0;32m    625\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m label_binarize(y_true, classes\u001B[38;5;241m=\u001B[39mlabels)[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_average_binary_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_binary_roc_auc_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_fpr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_fpr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# multilabel-indicator\u001B[39;00m\n\u001B[0;32m    634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _average_binary_score(\n\u001B[0;32m    635\u001B[0m         partial(_binary_roc_auc_score, max_fpr\u001B[38;5;241m=\u001B[39mmax_fpr),\n\u001B[0;32m    636\u001B[0m         y_true,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    639\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m    640\u001B[0m     )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001B[0m, in \u001B[0;36m_average_binary_score\u001B[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m format is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(y_type))\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbinary_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[0;32m     78\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:386\u001B[0m, in \u001B[0;36m_binary_roc_auc_score\u001B[1;34m(y_true, y_score, sample_weight, max_fpr)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y_true)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    382\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly one class present in y_true. ROC AUC score \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis not defined in that case.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    384\u001B[0m     )\n\u001B[1;32m--> 386\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m \u001B[43mroc_curve\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m max_fpr \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m auc(fpr, tpr)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    182\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1094\u001B[0m, in \u001B[0;36mroc_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m    993\u001B[0m     {\n\u001B[0;32m    994\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1003\u001B[0m     y_true, y_score, \u001B[38;5;241m*\u001B[39m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, drop_intermediate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1004\u001B[0m ):\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001B[39;00m\n\u001B[0;32m   1006\u001B[0m \n\u001B[0;32m   1007\u001B[0m \u001B[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1094\u001B[0m     fps, tps, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43m_binary_clf_curve\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1095\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m   1096\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1098\u001B[0m     \u001B[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1105\u001B[0m     \u001B[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001B[39;00m\n\u001B[0;32m   1106\u001B[0m     \u001B[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_intermediate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fps) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:807\u001B[0m, in \u001B[0;36m_binary_clf_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[0;32m    805\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[0;32m    806\u001B[0m y_true \u001B[38;5;241m=\u001B[39m column_or_1d(y_true)\n\u001B[1;32m--> 807\u001B[0m y_score \u001B[38;5;241m=\u001B[39m \u001B[43mcolumn_or_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    808\u001B[0m assert_all_finite(y_true)\n\u001B[0;32m    809\u001B[0m assert_all_finite(y_score)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1245\u001B[0m, in \u001B[0;36mcolumn_or_1d\u001B[1;34m(y, dtype, warn)\u001B[0m\n\u001B[0;32m   1234\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1235\u001B[0m             (\n\u001B[0;32m   1236\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA column-vector y was passed when a 1d array was\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1241\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   1242\u001B[0m         )\n\u001B[0;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _asarray_with_order(xp\u001B[38;5;241m.\u001B[39mreshape(y, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)), order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[1;32m-> 1245\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1246\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my should be a 1d array, got an array of shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shape)\n\u001B[0;32m   1247\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: y should be a 1d array, got an array of shape (27799, 2) instead."
     ]
    }
   ],
   "source": [
    "# [3] Define model\n",
    "model = model_constructor_4(C = best_model.C,\n",
    "                          gamma = best_model.gamma,\n",
    "                          probability = True,\n",
    "                          random_state = 0) # probability = True!!!\n",
    "\n",
    "# [4] Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(X_train)\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1))\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(y_train, pred_train, multi_class = 'ovo')\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test,multi_class = 'ovo')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:50:21.670958100Z",
     "start_time": "2023-09-29T15:43:21.698057500Z"
    }
   },
   "id": "b9efb2665d708350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print error\n",
    "print('AUC train = %.2f - AUC test = %.2f'\n",
    "      % (metric_train, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T15:20:27.316226700Z"
    }
   },
   "id": "2800652cb21a9d1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
