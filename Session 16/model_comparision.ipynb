{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:31:55.183400100Z",
     "start_time": "2023-10-04T14:31:55.160375900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../data/dataset_mock_midterm.csv', sep = \",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:41.104591300Z",
     "start_time": "2023-10-04T14:56:41.001897400Z"
    }
   },
   "id": "c491374bb21a305f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "          date  severity  mortality_ratio      age  num_proc  ambulatory  \\\n0      2016-01       NaN         0.408730  12596.0      21.0         0.0   \n1      2016-01       NaN         0.306931  20973.0      22.0         NaN   \n2      2016-01       4.0         0.278481  19611.0      19.0         NaN   \n3      2016-01       3.0         0.150289  13583.0      22.0         NaN   \n4      2016-01       1.0         0.016573  18042.0       2.0         NaN   \n...        ...       ...              ...      ...       ...         ...   \n32701  2016-12       2.0         0.028365  23619.0       2.0         NaN   \n32702  2016-12       1.0         0.000606   3935.0       1.0         NaN   \n32703  2016-12       NaN         0.040452  30163.0       4.0         NaN   \n32704  2016-12       NaN         0.000000  29012.0       4.0         NaN   \n32705  2016-12       NaN         0.000000  13244.0       1.0         NaN   \n\n       origin  expected_length tip_grd  tip_adm  exitus dataset  \n0         NaN            151.0       Q      1.0       0   train  \n1         NaN             99.0       Q      1.0       0   train  \n2         NaN             87.0     NaN      1.0       0   train  \n3         NaN            100.0       Q      NaN       0   train  \n4         NaN             44.0       Q      1.0       0   train  \n...       ...              ...     ...      ...     ...     ...  \n32701     NaN              2.0     NaN      1.0       0    test  \n32702     1.0              2.0       M      1.0       0    test  \n32703     NaN              2.0       M      NaN       0    test  \n32704     NaN              0.0     NaN      1.0       0    test  \n32705     NaN              0.0       Q      1.0       0    test  \n\n[32706 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.408730</td>\n      <td>12596.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>151.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.306931</td>\n      <td>20973.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>4.0</td>\n      <td>0.278481</td>\n      <td>19611.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>3.0</td>\n      <td>0.150289</td>\n      <td>13583.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.0</td>\n      <td>Q</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01</td>\n      <td>1.0</td>\n      <td>0.016573</td>\n      <td>18042.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>2016-12</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.040452</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:48:47.742842200Z",
     "start_time": "2023-09-29T13:48:47.706816500Z"
    }
   },
   "id": "48e440cbf290e985"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "dat.drop('date', axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:42.980058800Z",
     "start_time": "2023-10-04T14:56:42.954843900Z"
    }
   },
   "id": "24c865615d3a1b5d"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "cat_var = ['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
    "non_cat_var = list(set(dat.columns) - set(cat_var))\n",
    "num_var = list(set(dat.columns) - set(cat_var) - {'dataset', 'exitus'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:44.163428500Z",
     "start_time": "2023-10-04T14:56:44.141886300Z"
    }
   },
   "id": "cc5760f4ad76c83d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio     True\nage                 True\nnum_proc            True\nambulatory          True\norigin              True\nexpected_length     True\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:48:47.772618300Z",
     "start_time": "2023-09-29T13:48:47.742842200Z"
    }
   },
   "id": "5752a0bae798680"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory          True\norigin              True\nexpected_length    False\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fancyimpute import IterativeImputer as MICE\n",
    "# 3) Define \"model\"\n",
    "model = MICE()\n",
    "\n",
    "# 4) Train \"model\"\n",
    "model.fit(dat[num_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) \"Predict\"\n",
    "dat[num_var] = model.transform(dat[num_var])\n",
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:45.681313Z",
     "start_time": "2023-10-04T14:56:45.579055900Z"
    }
   },
   "id": "de1fc953f880a583"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "dat[cat_var] = dat[cat_var].astype('str')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:47.746317Z",
     "start_time": "2023-10-04T14:56:47.671871100Z"
    }
   },
   "id": "dc7e861007859a6a"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "severity      0\nambulatory    0\norigin        0\ntip_grd       0\ntip_adm       0\ndtype: int64"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.loc[dat['dataset'] == 'train', cat_var] = dat.loc[dat['dataset'] == 'train', cat_var].fillna('UNKNOWN')\n",
    "dat[cat_var][dat['dataset'] == 'train'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:48.482770800Z",
     "start_time": "2023-10-04T14:56:48.419155900Z"
    }
   },
   "id": "c50d041a2da326d"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "severity           False\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory         False\norigin             False\nexpected_length    False\ntip_grd            False\ntip_adm            False\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:52.719099200Z",
     "start_time": "2023-10-04T14:56:52.698556500Z"
    }
   },
   "id": "66f69e38ac9bfc1a"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False, drop='first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(dat[cat_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(dat[cat_var]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "dat = pd.concat((dat[non_cat_var], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:56:54.298856700Z",
     "start_time": "2023-10-04T14:56:54.235134600Z"
    }
   },
   "id": "4c5ed9b9152fb0f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 1 Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cc6d585039c438f"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as model_constructor_1\n",
    "from sklearn.metrics import roc_auc_score as metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:00.328468600Z",
     "start_time": "2023-10-04T14:57:00.299614700Z"
    }
   },
   "id": "afe9f1d1adaf586f"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "criterion_values = ['gini', 'entropy']\n",
    "max_depth_values = [5, 6, 7]\n",
    "min_samples_split_values = [10, 20, 30]\n",
    "min_samples_leaf_values = [29, 30, 31]\n",
    "max_features_values = [None, 1, 2]\n",
    "\n",
    "params_grid = {  'criterion': criterion_values,\n",
    "                 'max_depth': max_depth_values,\n",
    "                 'min_samples_split': min_samples_split_values,\n",
    "                 'min_samples_leaf': min_samples_leaf_values,\n",
    "                 'max_features': max_features_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:01.116604Z",
     "start_time": "2023-10-04T14:57:01.074478300Z"
    }
   },
   "id": "587950ec09aba8e2"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 iterations of Decision Tree\n"
     ]
    }
   ],
   "source": [
    "n = len(params_grid['max_depth'])*len(params_grid['min_samples_split'])*len(params_grid['min_samples_leaf'])*len(params_grid['max_features'])*len(params_grid['criterion'])\n",
    "print(str(n)+ ' iterations of Decision Tree')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:02.310604100Z",
     "start_time": "2023-10-04T14:57:02.272359900Z"
    }
   },
   "id": "d60199ee2d3354e9"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 2\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 3\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 4\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 5\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 6\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 7\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 8\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 9\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 10\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 11\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 12\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 13\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 14\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 15\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 16\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 17\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 18\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 19\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 20\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 21\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 22\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 23\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 24\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 25\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 26\n",
      "AUC train = 0.76 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 27\n",
      "AUC train = 0.83 - AUC validation = 0.81. Time spend = 0.04.\n",
      "Iteracion = 28\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 29\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 30\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 31\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 32\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 33\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 34\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.09.\n",
      "Iteracion = 35\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 36\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 37\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 38\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 39\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 40\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.08.\n",
      "Iteracion = 41\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 42\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 43\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.08.\n",
      "Iteracion = 44\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 45\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 46\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 47\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.03.\n",
      "Iteracion = 48\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 49\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.08.\n",
      "Iteracion = 50\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.04.\n",
      "Iteracion = 51\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 52\n",
      "AUC train = 0.95 - AUC validation = 0.94. Time spend = 0.08.\n",
      "Iteracion = 53\n",
      "AUC train = 0.71 - AUC validation = 0.68. Time spend = 0.03.\n",
      "Iteracion = 54\n",
      "AUC train = 0.87 - AUC validation = 0.84. Time spend = 0.04.\n",
      "Iteracion = 55\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 56\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 57\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 58\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 59\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.04.\n",
      "Iteracion = 60\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 61\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 62\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.04.\n",
      "Iteracion = 63\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 64\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 65\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 66\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 67\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 68\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 69\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 70\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 71\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 72\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 73\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 74\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 75\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 76\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.09.\n",
      "Iteracion = 77\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.04.\n",
      "Iteracion = 78\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 79\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.10.\n",
      "Iteracion = 80\n",
      "AUC train = 0.75 - AUC validation = 0.70. Time spend = 0.03.\n",
      "Iteracion = 81\n",
      "AUC train = 0.93 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 82\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 83\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 84\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 85\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 86\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 87\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 88\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 89\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 90\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 91\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 92\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 93\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 94\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 95\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 96\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 97\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.07.\n",
      "Iteracion = 98\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 99\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 100\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 101\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 102\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 103\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 104\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 105\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 106\n",
      "AUC train = 0.94 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 107\n",
      "AUC train = 0.75 - AUC validation = 0.74. Time spend = 0.04.\n",
      "Iteracion = 108\n",
      "AUC train = 0.92 - AUC validation = 0.89. Time spend = 0.04.\n",
      "Iteracion = 109\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 110\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.04.\n",
      "Iteracion = 111\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 112\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 113\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.04.\n",
      "Iteracion = 114\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 115\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 116\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.03.\n",
      "Iteracion = 117\n",
      "AUC train = 0.93 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 118\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 119\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.04.\n",
      "Iteracion = 120\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 121\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 122\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.04.\n",
      "Iteracion = 123\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 124\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 125\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.03.\n",
      "Iteracion = 126\n",
      "AUC train = 0.93 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 127\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 128\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.03.\n",
      "Iteracion = 129\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 130\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 131\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.04.\n",
      "Iteracion = 132\n",
      "AUC train = 0.90 - AUC validation = 0.88. Time spend = 0.04.\n",
      "Iteracion = 133\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 134\n",
      "AUC train = 0.72 - AUC validation = 0.71. Time spend = 0.03.\n",
      "Iteracion = 135\n",
      "AUC train = 0.93 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 136\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.09.\n",
      "Iteracion = 137\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 138\n",
      "AUC train = 0.91 - AUC validation = 0.90. Time spend = 0.04.\n",
      "Iteracion = 139\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 140\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.03.\n",
      "Iteracion = 141\n",
      "AUC train = 0.92 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 142\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 143\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 144\n",
      "AUC train = 0.88 - AUC validation = 0.86. Time spend = 0.04.\n",
      "Iteracion = 145\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.08.\n",
      "Iteracion = 146\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 147\n",
      "AUC train = 0.91 - AUC validation = 0.90. Time spend = 0.04.\n",
      "Iteracion = 148\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 149\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 150\n",
      "AUC train = 0.92 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 151\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 152\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.03.\n",
      "Iteracion = 153\n",
      "AUC train = 0.88 - AUC validation = 0.86. Time spend = 0.04.\n",
      "Iteracion = 154\n",
      "AUC train = 0.95 - AUC validation = 0.92. Time spend = 0.08.\n",
      "Iteracion = 155\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 156\n",
      "AUC train = 0.91 - AUC validation = 0.90. Time spend = 0.04.\n",
      "Iteracion = 157\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 158\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.04.\n",
      "Iteracion = 159\n",
      "AUC train = 0.92 - AUC validation = 0.91. Time spend = 0.04.\n",
      "Iteracion = 160\n",
      "AUC train = 0.95 - AUC validation = 0.93. Time spend = 0.08.\n",
      "Iteracion = 161\n",
      "AUC train = 0.74 - AUC validation = 0.73. Time spend = 0.03.\n",
      "Iteracion = 162\n",
      "AUC train = 0.88 - AUC validation = 0.86. Time spend = 0.04.\n",
      "Grid Search Total Computational Time:  8.617393502034247\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('criterion',\n",
    "                                       'max_depth',\n",
    "                                       'min_samples_split',\n",
    "                                       'min_samples_leaf',\n",
    "                                       'max_features',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for criterion in params_grid['criterion']:\n",
    "    for max_depth in params_grid['max_depth']:\n",
    "        for min_samples_split in params_grid['min_samples_split']:\n",
    "            for min_samples_leaf in params_grid['min_samples_leaf']:\n",
    "                for max_features in params_grid['max_features']:\n",
    "\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_1(criterion = criterion,\n",
    "                                              max_depth = max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf,\n",
    "                                              max_features = max_features,\n",
    "                                              random_state = 0)\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Evaluate\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[criterion,\n",
    "                                                max_depth,\n",
    "                                                min_samples_split,\n",
    "                                                min_samples_leaf,\n",
    "                                                max_features,\n",
    "                                             metric_train,\n",
    "                                             metric_val,\n",
    "                                            time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:14.162361Z",
     "start_time": "2023-10-04T14:57:05.394889600Z"
    }
   },
   "id": "a4d00e09cc98d9db"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "   criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n49      gini          6                 30                30         None   \n40      gini          6                 20                30         None   \n31      gini          6                 10                30         None   \n43      gini          6                 20                31         None   \n52      gini          6                 30                31         None   \n..       ...        ...                ...               ...          ...   \n32      gini          6                 10                30            1   \n38      gini          6                 20                29            1   \n35      gini          6                 10                31            1   \n50      gini          6                 30                30            1   \n44      gini          6                 20                31            1   \n\n    auc_train   auc_val      time  \n49   0.946581  0.935792  0.083802  \n40   0.946581  0.935792  0.084012  \n31   0.946581  0.935792  0.085513  \n43   0.946536  0.935474  0.083038  \n52   0.946536  0.935474  0.083105  \n..        ...       ...       ...  \n32   0.705386  0.681555  0.036915  \n38   0.705386  0.681555  0.037149  \n35   0.705386  0.681555  0.037361  \n50   0.705386  0.681555  0.038527  \n44   0.705386  0.681555  0.041744  \n\n[162 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>criterion</th>\n      <th>max_depth</th>\n      <th>min_samples_split</th>\n      <th>min_samples_leaf</th>\n      <th>max_features</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>49</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.083802</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.084012</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.085513</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.083038</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.083105</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.036915</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.037149</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.037361</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.038527</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.041744</td>\n    </tr>\n  </tbody>\n</table>\n<p>162 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:15.948968100Z",
     "start_time": "2023-10-04T14:57:15.925391600Z"
    }
   },
   "id": "27fa74f69d18afb0"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "criterion                gini\nmax_depth                   6\nmin_samples_split          30\nmin_samples_leaf           30\nmax_features             None\nauc_train            0.946581\nauc_val              0.935792\ntime                 0.083802\nName: 49, dtype: object"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:17.425380400Z",
     "start_time": "2023-10-04T14:57:17.402327400Z"
    }
   },
   "id": "c0e9831c027d57e8"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "model  = model_constructor_1(criterion = best_model['criterion'],\n",
    "                                              max_depth = best_model['max_depth'],\n",
    "                                              min_samples_split = best_model['min_samples_split'],\n",
    "                                              min_samples_leaf = best_model['min_samples_leaf'],\n",
    "                                              max_features = best_model['max_features'],\n",
    "                                              random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:18.644097100Z",
     "start_time": "2023-10-04T14:57:18.602298700Z"
    }
   },
   "id": "4cff231d011f886d"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=30,\n                       random_state=0)",
      "text/html": "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=30,\n                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=30,\n                       random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:20.122139500Z",
     "start_time": "2023-10-04T14:57:20.045499Z"
    }
   },
   "id": "56da93d4a4612391"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:22.881520500Z",
     "start_time": "2023-10-04T14:57:22.834258800Z"
    }
   },
   "id": "9f95ffa26429c2db"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.95 - Metric val = 0.94 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:24.158598900Z",
     "start_time": "2023-10-04T14:57:24.122035Z"
    }
   },
   "id": "b35cdf2c78ff3a5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying Oversampling and Subsampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c488699bc4716e"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       96.159726\n1        3.840274",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96.159726</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.840274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*dat.groupby(['exitus'])['exitus'].agg(['count'])/dat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:26.997798300Z",
     "start_time": "2023-10-04T14:57:26.978503100Z"
    }
   },
   "id": "5ed40644a1df459d"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_data = dat[dat['dataset'] == 'train']\n",
    "test_data = dat[dat['dataset'] == 'test']\n",
    "val_data = dat[dat['dataset'] == 'val']\n",
    "\n",
    "# Determine the minority class in the training data\n",
    "minority_class_len = min(train_data['exitus'].value_counts().tolist())\n",
    "\n",
    "# Subsample the majority class in the training data\n",
    "majority_class_indices = train_data[train_data['exitus'] == 0].index\n",
    "random_major_indices = np.random.choice(majority_class_indices, minority_class_len, replace=False)\n",
    "random_major_indices = np.array(random_major_indices)\n",
    "\n",
    "# Get the indices of the minority class in the training data\n",
    "minority_class_indices = train_data[train_data['exitus'] == 1].index\n",
    "\n",
    "# Concatenate the indices to create a balanced training dataset\n",
    "under_sample_indices = np.concatenate([minority_class_indices, random_major_indices])\n",
    "under_sample_train_data = train_data.loc[under_sample_indices]\n",
    "\n",
    "# Now, let's concatenate train, validation, and test to create data_new\n",
    "data_new = pd.concat([under_sample_train_data, val_data, test_data], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:42:02.019582100Z",
     "start_time": "2023-10-04T15:42:01.980055700Z"
    }
   },
   "id": "2c2e2da998ea5ba9"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "       exitus  expected_length  mortality_ratio dataset      age  num_proc  \\\n7           1             40.0         0.074278   train  21685.0       7.0   \n10          1             31.0         0.484536   train  31612.0       9.0   \n13          1             14.0         0.231884   train  24755.0      14.0   \n40          1             31.0         0.250000   train  17226.0      19.0   \n42          1             10.0         0.090515   train  28992.0       9.0   \n...       ...              ...              ...     ...      ...       ...   \n32701       0              2.0         0.028365    test  23619.0       2.0   \n32702       0              2.0         0.000606    test   3935.0       1.0   \n32703       0              2.0         0.040452    test  30163.0       4.0   \n32704       0              0.0         0.000000    test  29012.0       4.0   \n32705       0              0.0         0.000000    test  13244.0       1.0   \n\n       severity_2.0  severity_3.0  severity_4.0  severity_nan  ...  \\\n7               0.0           1.0           0.0           0.0  ...   \n10              0.0           0.0           1.0           0.0  ...   \n13              0.0           0.0           0.0           1.0  ...   \n40              0.0           0.0           0.0           1.0  ...   \n42              0.0           0.0           0.0           1.0  ...   \n...             ...           ...           ...           ...  ...   \n32701           1.0           0.0           0.0           0.0  ...   \n32702           0.0           0.0           0.0           0.0  ...   \n32703           0.0           0.0           0.0           1.0  ...   \n32704           0.0           0.0           0.0           1.0  ...   \n32705           0.0           0.0           0.0           1.0  ...   \n\n       origin_4.0  origin_6.0  origin_8.0  origin_9.0  origin_nan  tip_grd_Q  \\\n7             0.0         0.0         0.0         0.0         1.0        0.0   \n10            0.0         0.0         0.0         0.0         1.0        0.0   \n13            0.0         0.0         0.0         0.0         1.0        0.0   \n40            0.0         0.0         0.0         0.0         0.0        0.0   \n42            0.0         0.0         0.0         0.0         0.0        0.0   \n...           ...         ...         ...         ...         ...        ...   \n32701         0.0         0.0         0.0         0.0         1.0        0.0   \n32702         0.0         0.0         0.0         0.0         0.0        0.0   \n32703         0.0         0.0         0.0         0.0         1.0        0.0   \n32704         0.0         0.0         0.0         0.0         1.0        0.0   \n32705         0.0         0.0         0.0         0.0         1.0        1.0   \n\n       tip_grd_nan  tip_adm_2.0  tip_adm_3.0  tip_adm_nan  \n7              1.0          0.0          0.0          1.0  \n10             0.0          0.0          0.0          0.0  \n13             0.0          0.0          0.0          0.0  \n40             0.0          0.0          0.0          1.0  \n42             0.0          0.0          0.0          0.0  \n...            ...          ...          ...          ...  \n32701          1.0          0.0          0.0          0.0  \n32702          0.0          0.0          0.0          0.0  \n32703          0.0          0.0          0.0          1.0  \n32704          1.0          0.0          0.0          0.0  \n32705          0.0          0.0          0.0          0.0  \n\n[11582 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>exitus</th>\n      <th>expected_length</th>\n      <th>mortality_ratio</th>\n      <th>dataset</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>severity_2.0</th>\n      <th>severity_3.0</th>\n      <th>severity_4.0</th>\n      <th>severity_nan</th>\n      <th>...</th>\n      <th>origin_4.0</th>\n      <th>origin_6.0</th>\n      <th>origin_8.0</th>\n      <th>origin_9.0</th>\n      <th>origin_nan</th>\n      <th>tip_grd_Q</th>\n      <th>tip_grd_nan</th>\n      <th>tip_adm_2.0</th>\n      <th>tip_adm_3.0</th>\n      <th>tip_adm_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>40.0</td>\n      <td>0.074278</td>\n      <td>train</td>\n      <td>21685.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>31.0</td>\n      <td>0.484536</td>\n      <td>train</td>\n      <td>31612.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>14.0</td>\n      <td>0.231884</td>\n      <td>train</td>\n      <td>24755.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1</td>\n      <td>31.0</td>\n      <td>0.250000</td>\n      <td>train</td>\n      <td>17226.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1</td>\n      <td>10.0</td>\n      <td>0.090515</td>\n      <td>train</td>\n      <td>28992.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>test</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.000606</td>\n      <td>test</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.040452</td>\n      <td>test</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>test</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>test</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>11582 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:57:33.995520700Z",
     "start_time": "2023-10-04T14:57:33.951294900Z"
    }
   },
   "id": "c226dd268f56cffa"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       89.155586\n1       10.844414",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>89.155586</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.844414</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*data_new.groupby(['exitus'])['exitus'].agg(['count'])/data_new.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:42:05.600660100Z",
     "start_time": "2023-10-04T15:42:05.572218200Z"
    }
   },
   "id": "276d73aeffdc65c3"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With over-sampling methods, the number of samples in a class should be greater or equal to the original number of samples. Originally, there is 1256 samples and 80 samples are asked.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[116], line 9\u001B[0m\n\u001B[0;32m      4\u001B[0m sm \u001B[38;5;241m=\u001B[39m SMOTE(sampling_strategy \u001B[38;5;241m=\u001B[39m{\u001B[38;5;241m1\u001B[39m: \u001B[38;5;241m80\u001B[39m},\n\u001B[0;32m      5\u001B[0m            random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m      6\u001B[0m            k_neighbors \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Performing oversampling\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m X_res, y_res \u001B[38;5;241m=\u001B[39m \u001B[43msm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_new\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexitus\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdataset\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_new\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mexitus\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m X_res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexitus\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m y_res\n\u001B[0;32m     13\u001B[0m X_res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\imblearn\\base.py:208\u001B[0m, in \u001B[0;36mBaseSampler.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resample the dataset.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m    The corresponding label of `X_resampled`.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\imblearn\\base.py:108\u001B[0m, in \u001B[0;36mSamplerMixin.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    105\u001B[0m arrays_transformer \u001B[38;5;241m=\u001B[39m ArraysTransformer(X, y)\n\u001B[0;32m    106\u001B[0m X, y, binarize_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_X_y(X, y)\n\u001B[1;32m--> 108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy_ \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_sampling_strategy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampling_type\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_resample(X, y)\n\u001B[0;32m    114\u001B[0m y_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m     label_binarize(output[\u001B[38;5;241m1\u001B[39m], classes\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;28;01mif\u001B[39;00m binarize_y \u001B[38;5;28;01melse\u001B[39;00m output[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    116\u001B[0m )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\imblearn\\utils\\_validation.py:536\u001B[0m, in \u001B[0;36mcheck_sampling_strategy\u001B[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001B[0m\n\u001B[0;32m    531\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;28msorted\u001B[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type)\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    533\u001B[0m     )\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sampling_strategy, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[1;32m--> 536\u001B[0m         \u001B[38;5;28msorted\u001B[39m(\u001B[43m_sampling_strategy_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampling_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_type\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    537\u001B[0m     )\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sampling_strategy, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;28msorted\u001B[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type)\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    541\u001B[0m     )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\imblearn\\utils\\_validation.py:314\u001B[0m, in \u001B[0;36m_sampling_strategy_dict\u001B[1;34m(sampling_strategy, y, sampling_type)\u001B[0m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m class_sample, n_samples \u001B[38;5;129;01min\u001B[39;00m sampling_strategy\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m target_stats[class_sample]:\n\u001B[1;32m--> 314\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    315\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWith over-sampling methods, the number\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    316\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m of samples in a class should be greater\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    317\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or equal to the original number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    318\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Originally, there is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_stats[class_sample]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    319\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples are asked.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m             )\n\u001B[0;32m    321\u001B[0m         sampling_strategy_[class_sample] \u001B[38;5;241m=\u001B[39m n_samples \u001B[38;5;241m-\u001B[39m target_stats[class_sample]\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sampling_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munder-sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: With over-sampling methods, the number of samples in a class should be greater or equal to the original number of samples. Originally, there is 1256 samples and 80 samples are asked."
     ]
    }
   ],
   "source": [
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Initializing SMOTE object\n",
    "sm = SMOTE(sampling_strategy ={1: 80},\n",
    "           random_state = 0,\n",
    "           k_neighbors = 5)\n",
    "\n",
    "# Performing oversampling\n",
    "X_res, y_res = sm.fit_resample(data_new.drop(['exitus', 'dataset'], axis = 1), data_new['exitus'])\n",
    "\n",
    "X_res['exitus'] = y_res\n",
    "\n",
    "X_res['dataset'] = 'train'\n",
    "\n",
    "\n",
    "# Create new dataset after SMOTE.\n",
    "\n",
    "dat_smote = pd.concat([X_res, data_new[data_new['dataset'] == 'val'], data_new[data_new['dataset'] == 'test']])\n",
    "\n",
    "# Checking the class distribution after SMOTE\n",
    "100 * dat_smote.groupby(['exitus'])['exitus'].agg(['count']) / dat_smote.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T15:48:29.625862700Z",
     "start_time": "2023-10-04T15:48:29.540638400Z"
    }
   },
   "id": "79096c98a409b44d"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "criterion_values = ['gini', 'entropy']\n",
    "max_depth_values = [5, 6, 7]\n",
    "min_samples_split_values = [10, 20, 30]\n",
    "min_samples_leaf_values = [29, 30, 31]\n",
    "max_features_values = [None, 1, 2]\n",
    "\n",
    "params_grid = {  'criterion': criterion_values,\n",
    "                 'max_depth': max_depth_values,\n",
    "                 'min_samples_split': min_samples_split_values,\n",
    "                 'min_samples_leaf': min_samples_leaf_values,\n",
    "                 'max_features': max_features_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:49:00.821156200Z",
     "start_time": "2023-10-04T14:49:00.745130Z"
    }
   },
   "id": "a81c3d99895caf0e"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3789\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3790\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3791\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:152\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:181\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'dataset'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 33\u001B[0m\n\u001B[0;32m     25\u001B[0m model \u001B[38;5;241m=\u001B[39m model_constructor_1(criterion \u001B[38;5;241m=\u001B[39m criterion,\n\u001B[0;32m     26\u001B[0m                           max_depth \u001B[38;5;241m=\u001B[39m max_depth,\n\u001B[0;32m     27\u001B[0m                           min_samples_split \u001B[38;5;241m=\u001B[39m min_samples_split,\n\u001B[0;32m     28\u001B[0m                           min_samples_leaf \u001B[38;5;241m=\u001B[39m min_samples_leaf,\n\u001B[0;32m     29\u001B[0m                           max_features \u001B[38;5;241m=\u001B[39m max_features,\n\u001B[0;32m     30\u001B[0m                           random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# [4] Train model\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(dat[\u001B[43mdat\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdataset\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexitus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m),\n\u001B[0;32m     34\u001B[0m               dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mexitus\u001B[38;5;241m.\u001B[39mvalues)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# [5] Predict\u001B[39;00m\n\u001B[0;32m     37\u001B[0m pred_train \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexitus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m)) \u001B[38;5;66;03m# predict_proba!\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3894\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3895\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3896\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3897\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3898\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3792\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3793\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3794\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3795\u001B[0m     ):\n\u001B[0;32m   3796\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3797\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3798\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3799\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3800\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3801\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3802\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'dataset'"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('criterion',\n",
    "                                       'max_depth',\n",
    "                                       'min_samples_split',\n",
    "                                       'min_samples_leaf',\n",
    "                                       'max_features',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for criterion in params_grid['criterion']:\n",
    "    for max_depth in params_grid['max_depth']:\n",
    "        for min_samples_split in params_grid['min_samples_split']:\n",
    "            for min_samples_leaf in params_grid['min_samples_leaf']:\n",
    "                for max_features in params_grid['max_features']:\n",
    "\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_1(criterion = criterion,\n",
    "                                              max_depth = max_depth,\n",
    "                                              min_samples_split = min_samples_split,\n",
    "                                              min_samples_leaf = min_samples_leaf,\n",
    "                                              max_features = max_features,\n",
    "                                              random_state = 0)\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Evaluate\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[criterion,\n",
    "                                                max_depth,\n",
    "                                                min_samples_split,\n",
    "                                                min_samples_leaf,\n",
    "                                                max_features,\n",
    "                                             metric_train,\n",
    "                                             metric_val,\n",
    "                                            time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:49:02.914608500Z",
     "start_time": "2023-10-04T14:49:02.177313900Z"
    }
   },
   "id": "be2af55cc1194c0e"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "   criterion  max_depth  min_samples_split  min_samples_leaf max_features  \\\n40      gini          6                 20                30         None   \n31      gini          6                 10                30         None   \n49      gini          6                 30                30         None   \n34      gini          6                 10                31         None   \n43      gini          6                 20                31         None   \n..       ...        ...                ...               ...          ...   \n41      gini          6                 20                30            1   \n50      gini          6                 30                30            1   \n47      gini          6                 30                29            1   \n53      gini          6                 30                31            1   \n32      gini          6                 10                30            1   \n\n    auc_train   auc_val      time  \n40   0.946581  0.935792  0.082877  \n31   0.946581  0.935792  0.084940  \n49   0.946581  0.935792  0.086850  \n34   0.946536  0.935474  0.083728  \n43   0.946536  0.935474  0.085062  \n..        ...       ...       ...  \n41   0.705386  0.681555  0.034423  \n50   0.705386  0.681555  0.034950  \n47   0.705386  0.681555  0.035046  \n53   0.705386  0.681555  0.035978  \n32   0.705386  0.681555  0.040169  \n\n[162 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>criterion</th>\n      <th>max_depth</th>\n      <th>min_samples_split</th>\n      <th>min_samples_leaf</th>\n      <th>max_features</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>40</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.082877</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.084940</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>30</td>\n      <td>None</td>\n      <td>0.946581</td>\n      <td>0.935792</td>\n      <td>0.086850</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.083728</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>31</td>\n      <td>None</td>\n      <td>0.946536</td>\n      <td>0.935474</td>\n      <td>0.085062</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>20</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.034423</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.034950</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>29</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.035046</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>30</td>\n      <td>31</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.035978</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>gini</td>\n      <td>6</td>\n      <td>10</td>\n      <td>30</td>\n      <td>1</td>\n      <td>0.705386</td>\n      <td>0.681555</td>\n      <td>0.040169</td>\n    </tr>\n  </tbody>\n</table>\n<p>162 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:46:39.325713500Z",
     "start_time": "2023-10-04T14:46:39.276273600Z"
    }
   },
   "id": "bc7069a545c889ea"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "criterion                gini\nmax_depth                   6\nmin_samples_split          20\nmin_samples_leaf           30\nmax_features             None\nauc_train            0.946581\nauc_val              0.935792\ntime                 0.082877\nName: 40, dtype: object"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:47:23.059354600Z",
     "start_time": "2023-10-04T14:47:22.965904700Z"
    }
   },
   "id": "643f7944c413536b"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "model  = model_constructor_1(criterion = best_model['criterion'],\n",
    "                                              max_depth = best_model['max_depth'],\n",
    "                                              min_samples_split = best_model['min_samples_split'],\n",
    "                                              min_samples_leaf = best_model['min_samples_leaf'],\n",
    "                                              max_features = best_model['max_features'],\n",
    "                                              random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:47:30.469395900Z",
     "start_time": "2023-10-04T14:47:30.349734800Z"
    }
   },
   "id": "df34881762d8f3fd"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=6, min_samples_leaf=30, min_samples_split=20,\n                       random_state=0)</pre></div></div></div></div></div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:47:38.193129100Z",
     "start_time": "2023-10-04T14:47:37.973295800Z"
    }
   },
   "id": "521039837f9fac86"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:47:47.656325300Z",
     "start_time": "2023-10-04T14:47:47.516270700Z"
    }
   },
   "id": "2ca39057c329008c"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.95 - Metric val = 0.94 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-04T14:47:54.518143Z",
     "start_time": "2023-10-04T14:47:54.419321400Z"
    }
   },
   "id": "367edddccee39036"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "61c89d20a9dd4de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 2 Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c3bc82b733bc28a"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor_2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:48:57.922714700Z",
     "start_time": "2023-09-29T13:48:57.716559700Z"
    }
   },
   "id": "d87263ca05fa8b7e"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_estimators_values = [10, 100, 1000]\n",
    "max_features_values = [2, 5, 10]\n",
    "max_samples_values = [100, 1000, dat[dat['dataset'] == 'train'].shape[0]]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:48:57.924225Z",
     "start_time": "2023-09-29T13:48:57.752719800Z"
    }
   },
   "id": "ddeec08166838024"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.84 - Metric validation = 0.82.\n",
      "Iteracion = 2\n",
      "Metric train = 0.90 - Metric validation = 0.85.\n",
      "Iteracion = 3\n",
      "Metric train = 1.00 - Metric validation = 0.84.\n",
      "Iteracion = 4\n",
      "Metric train = 0.93 - Metric validation = 0.93.\n",
      "Iteracion = 5\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteracion = 6\n",
      "Metric train = 1.00 - Metric validation = 0.92.\n",
      "Iteracion = 7\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteracion = 8\n",
      "Metric train = 0.97 - Metric validation = 0.94.\n",
      "Iteracion = 9\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n",
      "Iteracion = 10\n",
      "Metric train = 0.86 - Metric validation = 0.85.\n",
      "Iteracion = 11\n",
      "Metric train = 0.90 - Metric validation = 0.86.\n",
      "Iteracion = 12\n",
      "Metric train = 1.00 - Metric validation = 0.86.\n",
      "Iteracion = 13\n",
      "Metric train = 0.93 - Metric validation = 0.92.\n",
      "Iteracion = 14\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteracion = 15\n",
      "Metric train = 1.00 - Metric validation = 0.92.\n",
      "Iteracion = 16\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteracion = 17\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteracion = 18\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n",
      "Iteracion = 19\n",
      "Metric train = 0.87 - Metric validation = 0.85.\n",
      "Iteracion = 20\n",
      "Metric train = 0.90 - Metric validation = 0.86.\n",
      "Iteracion = 21\n",
      "Metric train = 1.00 - Metric validation = 0.84.\n",
      "Iteracion = 22\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteracion = 23\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteracion = 24\n",
      "Metric train = 1.00 - Metric validation = 0.92.\n",
      "Iteracion = 25\n",
      "Metric train = 0.94 - Metric validation = 0.93.\n",
      "Iteracion = 26\n",
      "Metric train = 0.96 - Metric validation = 0.94.\n",
      "Iteracion = 27\n",
      "Metric train = 1.00 - Metric validation = 0.93.\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor_2(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "                        pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                        metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:50:52.327302200Z",
     "start_time": "2023-09-29T13:48:57.760462800Z"
    }
   },
   "id": "9883eb3ff1deee2e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features      10.000000\nn_estimators    1000.000000\nmax_samples     1000.000000\nmetric_train       0.961979\nmetric_val         0.937384\nName: 26, dtype: float64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:50:52.345213200Z",
     "start_time": "2023-09-29T13:50:52.328301200Z"
    }
   },
   "id": "116791af06edcb42"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                var           imp\n1   mortality_ratio  3.213752e-01\n0               age  2.589571e-01\n3   expected_length  1.476638e-01\n2          num_proc  1.153729e-01\n18      tip_grd_nan  2.751719e-02\n16       origin_nan  2.720553e-02\n21      tip_adm_nan  2.160280e-02\n6      severity_4.0  1.794256e-02\n7      severity_nan  1.489820e-02\n5      severity_3.0  1.338546e-02\n9    ambulatory_nan  1.105673e-02\n4      severity_2.0  5.555941e-03\n17        tip_grd_Q  5.428211e-03\n19      tip_adm_2.0  5.200937e-03\n20      tip_adm_3.0  2.762846e-03\n13       origin_6.0  2.100151e-03\n12       origin_4.0  8.708548e-04\n10       origin_2.0  5.381107e-04\n15       origin_9.0  2.781852e-04\n11       origin_3.0  2.737243e-04\n8    ambulatory_1.0  1.348364e-05\n14       origin_8.0  4.084932e-08",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var</th>\n      <th>imp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>mortality_ratio</td>\n      <td>3.213752e-01</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>age</td>\n      <td>2.589571e-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>expected_length</td>\n      <td>1.476638e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>num_proc</td>\n      <td>1.153729e-01</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>tip_grd_nan</td>\n      <td>2.751719e-02</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>origin_nan</td>\n      <td>2.720553e-02</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>tip_adm_nan</td>\n      <td>2.160280e-02</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>severity_4.0</td>\n      <td>1.794256e-02</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>severity_nan</td>\n      <td>1.489820e-02</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>severity_3.0</td>\n      <td>1.338546e-02</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ambulatory_nan</td>\n      <td>1.105673e-02</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>severity_2.0</td>\n      <td>5.555941e-03</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>tip_grd_Q</td>\n      <td>5.428211e-03</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>tip_adm_2.0</td>\n      <td>5.200937e-03</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>tip_adm_3.0</td>\n      <td>2.762846e-03</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>origin_6.0</td>\n      <td>2.100151e-03</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>origin_4.0</td>\n      <td>8.708548e-04</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>origin_2.0</td>\n      <td>5.381107e-04</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>origin_9.0</td>\n      <td>2.781852e-04</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>origin_3.0</td>\n      <td>2.737243e-04</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ambulatory_1.0</td>\n      <td>1.348364e-05</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>origin_8.0</td>\n      <td>4.084932e-08</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract variable importance (tree-based)\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "var_imp = pd.DataFrame({'var': dat.drop(['exitus', 'dataset'], axis = 1).columns, 'imp': model.feature_importances_})\n",
    "var_imp.sort_values(['imp'], ascending = False, inplace = True)\n",
    "var_imp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:51:28.033192800Z",
     "start_time": "2023-09-29T13:50:52.333815600Z"
    }
   },
   "id": "e0f1d6ba24700f98"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "dat = dat[['mortality_ratio', 'age', 'expected_length', 'num_proc', 'exitus', 'dataset']] # This is just a fake example of how to select the most important variables."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:51:28.037961200Z",
     "start_time": "2023-09-29T13:51:28.032189500Z"
    }
   },
   "id": "553dff2f58aa3afd"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.280773200Z",
     "start_time": "2023-09-29T13:51:28.039964200Z"
    }
   },
   "id": "b9645cf6d73b105c"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 1.00 - Metric val = 0.92 - Metric test = 0.93\n"
     ]
    }
   ],
   "source": [
    "# print error\n",
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.287810100Z",
     "start_time": "2023-09-29T13:52:22.281774400Z"
    }
   },
   "id": "8443653ec903fb25"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 3 XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91082899d3525ad3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as model_constructor_3\n",
    "\n",
    "model = model_constructor_3(early_stopping_rounds=10,\n",
    "                            n_estimators=1000,\n",
    "                            eval_metric=\"auc\",\n",
    "                            random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.350936800Z",
     "start_time": "2023-09-29T13:52:22.286812700Z"
    }
   },
   "id": "4994fea304b523d8"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.92578\n",
      "[1]\tvalidation_0-auc:0.92765\n",
      "[2]\tvalidation_0-auc:0.92970\n",
      "[3]\tvalidation_0-auc:0.93286\n",
      "[4]\tvalidation_0-auc:0.93248\n",
      "[5]\tvalidation_0-auc:0.93186\n",
      "[6]\tvalidation_0-auc:0.93142\n",
      "[7]\tvalidation_0-auc:0.93240\n",
      "[8]\tvalidation_0-auc:0.93261\n",
      "[9]\tvalidation_0-auc:0.93175\n",
      "[10]\tvalidation_0-auc:0.93247\n",
      "[11]\tvalidation_0-auc:0.93232\n",
      "[12]\tvalidation_0-auc:0.93241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric='auc', feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=&#x27;auc&#x27;, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=1000, n_jobs=None,\n              num_parallel_tree=None, random_state=1, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "          np.array(dat[dat['dataset'] == 'train'].exitus.values),\n",
    "          eval_set=[(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'val'].exitus.values)], \n",
    "          verbose=True,\n",
    "          )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.538109800Z",
     "start_time": "2023-09-29T13:52:22.336420500Z"
    }
   },
   "id": "5b6b770fbd8885e0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:335: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:338: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  is_categorical_dtype(dtype) or is_pa_ext_categorical_dtype(dtype)\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:384: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if is_categorical_dtype(dtype):\n",
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\xgboost\\data.py:359: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  return is_int or is_bool or is_float or is_categorical_dtype(dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": "               model  auc_train   auc_val  auc_test\n0  XGBoost (Default)   0.954507  0.932856  0.934233",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>auc_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XGBoost (Default)</td>\n      <td>0.954507</td>\n      <td>0.932856</td>\n      <td>0.934233</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train_p = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_val_p = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_test_p = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1))\n",
    "# Calcular métricas de evaluación\n",
    "auc_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train_p[:,1])\n",
    "auc_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val_p[:,1])\n",
    "auc_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test_p[:,1])\n",
    "results = pd.DataFrame()\n",
    "\n",
    "new_data = pd.DataFrame(data={'model': ['XGBoost (Default)'], 'auc_train': [auc_train], 'auc_val': [auc_val], 'auc_test': [auc_test]}, columns=['model', 'auc_train', 'auc_val', 'auc_test'])\n",
    "\n",
    "results = pd.concat([results, new_data], ignore_index=True)\n",
    "\n",
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.557159200Z",
     "start_time": "2023-09-29T13:52:22.430246Z"
    }
   },
   "id": "101b847763be4c61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model 4 SVM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d80eac6d1b84c35"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as model_constructor_4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.559157500Z",
     "start_time": "2023-09-29T13:52:22.473178700Z"
    }
   },
   "id": "2747fa5e7c129037"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "d = dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1).shape[1]\n",
    "m = np.mean(dat[dat['dataset'] == 'train'].exitus.values)\n",
    "s = np.std(dat[dat['dataset'] == 'train'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.562664700Z",
     "start_time": "2023-09-29T13:52:22.476920100Z"
    }
   },
   "id": "441dbe1a1ab3d3d6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "C_cherk = np.max([np.abs(m + 3*s),np.abs(m - 3*s)])\n",
    "gamma_cherk = np.power(0.2, 1/d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.632191200Z",
     "start_time": "2023-09-29T13:52:22.501513100Z"
    }
   },
   "id": "21aad612055aad55"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# SVM\n",
    "C_values = [0.1, 1, 10]\n",
    "gamma_values = [0.01, 1, 100]\n",
    "\n",
    "params_grid = {'C': C_values,\n",
    "               'gamma': gamma_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T13:52:22.640715Z",
     "start_time": "2023-09-29T13:52:22.526083700Z"
    }
   },
   "id": "b8107d133f646f5b"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "AUC train = 0.03 - AUC validation = 0.45. Time spend = 171.62.\n",
      "Iteracion = 2\n",
      "AUC train = 0.00 - AUC validation = 0.33. Time spend = 532.83.\n",
      "Iteracion = 3\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 594.49.\n",
      "Iteracion = 4\n",
      "AUC train = 0.03 - AUC validation = 0.45. Time spend = 300.82.\n",
      "Iteracion = 5\n",
      "AUC train = 0.00 - AUC validation = 0.32. Time spend = 714.31.\n",
      "Iteracion = 6\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 784.88.\n",
      "Iteracion = 7\n",
      "AUC train = 0.98 - AUC validation = 0.51. Time spend = 283.18.\n",
      "Iteracion = 8\n",
      "AUC train = 0.00 - AUC validation = 0.32. Time spend = 747.88.\n",
      "Iteracion = 9\n",
      "AUC train = 0.00 - AUC validation = 0.49. Time spend = 757.84.\n",
      "Grid Search Total Computational Time:  4887.841272299993\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('C',\n",
    "                                       'gamma',\n",
    "                                       'auc_train',\n",
    "                                       'auc_val',\n",
    "                                       'time'))\n",
    "\n",
    "for C in params_grid['C']:\n",
    "    for gamma in params_grid['gamma']:\n",
    "\n",
    "                    # Start time\n",
    "                    start_time = default_timer()\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor_4(C = C,\n",
    "                                              gamma = gamma,\n",
    "                                              probability = True,\n",
    "                                              random_state = 0) # Probability = True!!!\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Compute metric\n",
    "                    metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,0])\n",
    "                    metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,0])\n",
    "\n",
    "                    # Computational time\n",
    "                    time = default_timer() - start_time\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f. Time spend = %.2f.'\n",
    "                          % (metric_train, metric_val, time))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[C,\n",
    "                                                gamma,\n",
    "                                                metric_train,\n",
    "                                                metric_val,\n",
    "                                                time]\n",
    "                    num_iter += 1\n",
    "\n",
    "print('Grid Search Total Computational Time: ', np.sum(grid_results.time.values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.475704400Z",
     "start_time": "2023-09-29T13:52:22.540109300Z"
    }
   },
   "id": "6e4502ed9fb8fe19"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "      C   gamma  auc_train   auc_val        time\n7  10.0    0.01   0.980731  0.508097  283.183016\n9  10.0  100.00   0.000000  0.488844  757.837903\n6   1.0  100.00   0.000000  0.488810  784.881326\n3   0.1  100.00   0.000000  0.488769  594.486062\n4   1.0    0.01   0.031175  0.453393  300.823236\n1   0.1    0.01   0.034346  0.452615  171.616194\n2   0.1    1.00   0.000000  0.326914  532.830954\n5   1.0    1.00   0.000000  0.324975  714.305631\n8  10.0    1.00   0.000000  0.324802  747.876950",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C</th>\n      <th>gamma</th>\n      <th>auc_train</th>\n      <th>auc_val</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7</th>\n      <td>10.0</td>\n      <td>0.01</td>\n      <td>0.980731</td>\n      <td>0.508097</td>\n      <td>283.183016</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10.0</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488844</td>\n      <td>757.837903</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.0</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488810</td>\n      <td>784.881326</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.1</td>\n      <td>100.00</td>\n      <td>0.000000</td>\n      <td>0.488769</td>\n      <td>594.486062</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.01</td>\n      <td>0.031175</td>\n      <td>0.453393</td>\n      <td>300.823236</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.1</td>\n      <td>0.01</td>\n      <td>0.034346</td>\n      <td>0.452615</td>\n      <td>171.616194</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.1</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.326914</td>\n      <td>532.830954</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.324975</td>\n      <td>714.305631</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>10.0</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.324802</td>\n      <td>747.876950</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['auc_val', 'auc_train', 'time'], ascending = [False, False, True])\n",
    "grid_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.492099900Z",
     "start_time": "2023-09-29T15:13:50.477702200Z"
    }
   },
   "id": "cead764708e98a9d"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "C             10.000000\ngamma          0.010000\nauc_train      0.980731\nauc_val        0.508097\ntime         283.183016\nName: 7, dtype: float64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.506416200Z",
     "start_time": "2023-09-29T15:13:50.492099900Z"
    }
   },
   "id": "1d5370c40ced0dc9"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old train data size = (22894, 4)\n",
      "Old train target size = (22894,)\n",
      "New train data size = (27799, 4)\n",
      "New train target size = (27799,)\n"
     ]
    }
   ],
   "source": [
    "print('Old train data size = ' + str(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1).shape))\n",
    "print('Old train target size = ' + str(dat[dat['dataset'] == 'train'].exitus.values.shape))\n",
    "\n",
    "# Combine train and validación\n",
    "X_train = np.concatenate((dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)), axis = 0)\n",
    "y_train = np.concatenate((dat[dat['dataset'] == 'train'].exitus.values, dat[dat['dataset'] == 'val'].exitus.values), axis = 0)\n",
    "\n",
    "print('New train data size = ' + str(X_train.shape))\n",
    "print('New train target size = ' + str(y_train.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:13:50.592511200Z",
     "start_time": "2023-09-29T15:13:50.507413900Z"
    }
   },
   "id": "4ad072ceeabca1cb"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but SVC was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (27799, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[42], line 15\u001B[0m\n\u001B[0;32m     12\u001B[0m pred_test \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mexitus\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# [6] Compute metric\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m metric_train \u001B[38;5;241m=\u001B[39m \u001B[43mmetric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43movo\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     16\u001B[0m metric_test \u001B[38;5;241m=\u001B[39m metric(dat[dat[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mexitus\u001B[38;5;241m.\u001B[39mvalues, pred_test,multi_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:626\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    624\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n\u001B[0;32m    625\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m label_binarize(y_true, classes\u001B[38;5;241m=\u001B[39mlabels)[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_average_binary_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_binary_roc_auc_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_fpr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_fpr\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    629\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    630\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# multilabel-indicator\u001B[39;00m\n\u001B[0;32m    634\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _average_binary_score(\n\u001B[0;32m    635\u001B[0m         partial(_binary_roc_auc_score, max_fpr\u001B[38;5;241m=\u001B[39mmax_fpr),\n\u001B[0;32m    636\u001B[0m         y_true,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    639\u001B[0m         sample_weight\u001B[38;5;241m=\u001B[39msample_weight,\n\u001B[0;32m    640\u001B[0m     )\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_base.py:75\u001B[0m, in \u001B[0;36m_average_binary_score\u001B[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001B[0m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m format is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(y_type))\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbinary_metric\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[0;32m     78\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:386\u001B[0m, in \u001B[0;36m_binary_roc_auc_score\u001B[1;34m(y_true, y_score, sample_weight, max_fpr)\u001B[0m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39munique(y_true)) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    381\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    382\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOnly one class present in y_true. ROC AUC score \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis not defined in that case.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    384\u001B[0m     )\n\u001B[1;32m--> 386\u001B[0m fpr, tpr, _ \u001B[38;5;241m=\u001B[39m \u001B[43mroc_curve\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m max_fpr \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m auc(fpr, tpr)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    182\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    188\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:1094\u001B[0m, in \u001B[0;36mroc_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001B[0m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m    993\u001B[0m     {\n\u001B[0;32m    994\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1003\u001B[0m     y_true, y_score, \u001B[38;5;241m*\u001B[39m, pos_label\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, drop_intermediate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1004\u001B[0m ):\n\u001B[0;32m   1005\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001B[39;00m\n\u001B[0;32m   1006\u001B[0m \n\u001B[0;32m   1007\u001B[0m \u001B[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;124;03m    array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1094\u001B[0m     fps, tps, thresholds \u001B[38;5;241m=\u001B[39m \u001B[43m_binary_clf_curve\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1095\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m   1096\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1098\u001B[0m     \u001B[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m     \u001B[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1105\u001B[0m     \u001B[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001B[39;00m\n\u001B[0;32m   1106\u001B[0m     \u001B[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m drop_intermediate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fps) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:807\u001B[0m, in \u001B[0;36m_binary_clf_curve\u001B[1;34m(y_true, y_score, pos_label, sample_weight)\u001B[0m\n\u001B[0;32m    805\u001B[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001B[0;32m    806\u001B[0m y_true \u001B[38;5;241m=\u001B[39m column_or_1d(y_true)\n\u001B[1;32m--> 807\u001B[0m y_score \u001B[38;5;241m=\u001B[39m \u001B[43mcolumn_or_1d\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    808\u001B[0m assert_all_finite(y_true)\n\u001B[0;32m    809\u001B[0m assert_all_finite(y_score)\n",
      "File \u001B[1;32mJ:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1245\u001B[0m, in \u001B[0;36mcolumn_or_1d\u001B[1;34m(y, dtype, warn)\u001B[0m\n\u001B[0;32m   1234\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1235\u001B[0m             (\n\u001B[0;32m   1236\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA column-vector y was passed when a 1d array was\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1241\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   1242\u001B[0m         )\n\u001B[0;32m   1243\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _asarray_with_order(xp\u001B[38;5;241m.\u001B[39mreshape(y, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,)), order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m, xp\u001B[38;5;241m=\u001B[39mxp)\n\u001B[1;32m-> 1245\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1246\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my should be a 1d array, got an array of shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(shape)\n\u001B[0;32m   1247\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: y should be a 1d array, got an array of shape (27799, 2) instead."
     ]
    }
   ],
   "source": [
    "# [3] Define model\n",
    "model = model_constructor_4(C = best_model.C,\n",
    "                          gamma = best_model.gamma,\n",
    "                          probability = True,\n",
    "                          random_state = 0) # probability = True!!!\n",
    "\n",
    "# [4] Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(X_train)\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1))\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(y_train, pred_train, multi_class = 'ovo')\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test,multi_class = 'ovo')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T15:50:21.670958100Z",
     "start_time": "2023-09-29T15:43:21.698057500Z"
    }
   },
   "id": "b9efb2665d708350"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print error\n",
    "print('AUC train = %.2f - AUC test = %.2f'\n",
    "      % (metric_train, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T15:20:27.316226700Z"
    }
   },
   "id": "2800652cb21a9d1e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
