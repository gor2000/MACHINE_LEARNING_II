{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.402493300Z",
     "start_time": "2023-10-10T08:02:04.971516100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../data/dataset_mock_final.csv', sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.421901700Z",
     "start_time": "2023-10-10T08:02:06.389386500Z"
    }
   },
   "id": "573f6ec5b07eec6e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      date  severity  mortality_ratio      age  num_proc  ambulatory  origin  \\\n0  2016-07       NaN         0.001193  15603.0       4.0         NaN     NaN   \n1  2016-05       1.0         0.000000  14285.0       3.0         NaN     1.0   \n2  2016-01       NaN         0.000000   6046.0       2.0         NaN     NaN   \n3  2016-01       1.0         0.004060  27340.0       4.0         NaN     2.0   \n4  2016-05       2.0         0.028365  28685.0      10.0         0.0     NaN   \n\n   expected_length tip_grd  tip_adm  exitus dataset  \n0              7.0       M      1.0       0   train  \n1              NaN       M      1.0       0   train  \n2              2.0     NaN      1.0       0   train  \n3              9.0       Q      NaN       0   train  \n4              9.0       M      1.0       0   train  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-07</td>\n      <td>NaN</td>\n      <td>0.001193</td>\n      <td>15603.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-05</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>14285.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>6046.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>1.0</td>\n      <td>0.004060</td>\n      <td>27340.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>9.0</td>\n      <td>Q</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-05</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>28685.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.463636800Z",
     "start_time": "2023-10-10T08:02:06.420388400Z"
    }
   },
   "id": "37541974e5419883"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dat.drop('date', axis = 1, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.467754500Z",
     "start_time": "2023-10-10T08:02:06.440724600Z"
    }
   },
   "id": "fe82a7a5e4fa1ae0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cat_var = ['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
    "non_cat_var = list(set(dat.columns) - set(cat_var))\n",
    "num_var = list(set(dat.columns) - set(cat_var) - {'dataset', 'exitus'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.467754500Z",
     "start_time": "2023-10-10T08:02:06.450687400Z"
    }
   },
   "id": "ad6e3d2019bac20c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio     True\nage                 True\nnum_proc            True\nambulatory          True\norigin              True\nexpected_length     True\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:06.497880600Z",
     "start_time": "2023-10-10T08:02:06.457123700Z"
    }
   },
   "id": "5a446d957539bf34"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:796: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "severity            True\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory          True\norigin              True\nexpected_length    False\ntip_grd             True\ntip_adm             True\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from fancyimpute import IterativeImputer as MICE\n",
    "\n",
    "# 3) Define \"model\"\n",
    "model = MICE(estimator=RandomForestRegressor())\n",
    "\n",
    "# 4) Train \"model\"\n",
    "model.fit(dat[num_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) \"Predict\"\n",
    "dat[num_var] = model.transform(dat[num_var])\n",
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.798456300Z",
     "start_time": "2023-10-10T08:02:06.468752Z"
    }
   },
   "id": "4d8798c45537d087"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dat[cat_var] = dat[cat_var].astype('str')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.820283300Z",
     "start_time": "2023-10-10T08:02:27.797454400Z"
    }
   },
   "id": "fdd5fa2fe722455"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "severity      0\nambulatory    0\norigin        0\ntip_grd       0\ntip_adm       0\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.loc[dat['dataset'] == 'train', cat_var] = dat.loc[dat['dataset'] == 'train', cat_var].fillna('UNKNOWN')\n",
    "dat[cat_var][dat['dataset'] == 'train'].isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.850686300Z",
     "start_time": "2023-10-10T08:02:27.820789Z"
    }
   },
   "id": "48bea39e65e51e56"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "severity           False\nmortality_ratio    False\nage                False\nnum_proc           False\nambulatory         False\norigin             False\nexpected_length    False\ntip_grd            False\ntip_adm            False\nexitus             False\ndataset            False\ndtype: bool"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.870548800Z",
     "start_time": "2023-10-10T08:02:27.852694500Z"
    }
   },
   "id": "9111da8033d3fe13"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse_output = False, drop='first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(dat[cat_var][dat['dataset'] == 'train'])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(dat[cat_var]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "dat = pd.concat((dat[non_cat_var], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.926406500Z",
     "start_time": "2023-10-10T08:02:27.860294300Z"
    }
   },
   "id": "2098765cd5d77c54"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       96.235664\n1        3.764336",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96.235664</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.764336</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*dat.groupby(['exitus'])['exitus'].agg(['count'])/dat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.947320400Z",
     "start_time": "2023-10-10T08:02:27.904352800Z"
    }
   },
   "id": "b736fa89a2230c2f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a 10.0% minority class after oversampling, set sampling_strategy to 0.11 in SMOTE.\n"
     ]
    }
   ],
   "source": [
    "def compute_sampling_strategy(frac_minority, minority_count, majority_count):\n",
    "    synthetic_samples = (frac_minority * majority_count - (1 - frac_minority) * minority_count) / (1 - frac_minority)\n",
    "    strategy = (minority_count + synthetic_samples) / majority_count\n",
    "    return strategy\n",
    "\n",
    "# Assume you have counts for your classes\n",
    "minority_count = sum(dat['exitus'] == 1)\n",
    "majority_count = sum(dat['exitus'] == 0)\n",
    "\n",
    "# For a 10-90 split:\n",
    "fraction = 0.1\n",
    "sampling_value = compute_sampling_strategy(fraction, minority_count, majority_count)\n",
    "print(f\"For a {fraction*100}% minority class after oversampling, set sampling_strategy to {sampling_value:.2f} in SMOTE.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:27.958847400Z",
     "start_time": "2023-10-10T08:02:27.933556500Z"
    }
   },
   "id": "6b0eac26d0d4b00"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "%%capture\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy =sampling_value,\n",
    "           random_state = 0,\n",
    "           k_neighbors = 5)\n",
    "\n",
    "X_res, y_res = sm.fit_resample(dat.drop(['exitus', 'dataset'], axis = 1), dat['exitus'])\n",
    "\n",
    "X_res['exitus'] = y_res\n",
    "\n",
    "X_res['dataset'] = 'train'\n",
    "\n",
    "dat_new = pd.concat([X_res, dat[dat['dataset'] == 'val'], dat[dat['dataset'] == 'test']])\n",
    "\n",
    "# Checking the class distribution after SMOTE\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:28.572014900Z",
     "start_time": "2023-10-10T08:02:27.939278800Z"
    }
   },
   "id": "c90d87426415cbe0"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "exitus\n0    90.000865\n1     9.999135\nName: count, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*X_res.exitus.value_counts()/X_res.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:28.591843700Z",
     "start_time": "2023-10-10T08:02:28.572014900Z"
    }
   },
   "id": "3b8f25b659038c5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51b4111f471f56a4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score as metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:28.593852700Z",
     "start_time": "2023-10-10T08:02:28.581797800Z"
    }
   },
   "id": "84e8b9259e8b7e69"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:28.612974600Z",
     "start_time": "2023-10-10T08:02:28.590833200Z"
    }
   },
   "id": "ed7f2078d86555d5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "n_estimators_values = [120, 140, 150]\n",
    "max_features_values = [3, 4, 5, 6]\n",
    "max_samples_values = [60, 80, 100, 120]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:28.634019100Z",
     "start_time": "2023-10-10T08:02:28.601188900Z"
    }
   },
   "id": "6464da92227999ac"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 2\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 3\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 4\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 5\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 6\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 7\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 8\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 9\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 10\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 11\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 12\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 13\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 14\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 15\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 16\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 17\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 18\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 19\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 20\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 21\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 22\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 23\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 24\n",
      "Metric train = 0.98 - Metric validation = 0.92.\n",
      "Iteracion = 25\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteracion = 26\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 27\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 28\n",
      "Metric train = 0.98 - Metric validation = 0.91.\n",
      "Iteracion = 29\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteracion = 30\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 31\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 32\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 33\n",
      "Metric train = 0.96 - Metric validation = 0.93.\n",
      "Iteracion = 34\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 35\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 36\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 37\n",
      "Metric train = 0.95 - Metric validation = 0.92.\n",
      "Iteracion = 38\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 39\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 40\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 41\n",
      "Metric train = 0.95 - Metric validation = 0.92.\n",
      "Iteracion = 42\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 43\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 44\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 45\n",
      "Metric train = 0.95 - Metric validation = 0.92.\n",
      "Iteracion = 46\n",
      "Metric train = 0.96 - Metric validation = 0.92.\n",
      "Iteracion = 47\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n",
      "Iteracion = 48\n",
      "Metric train = 0.97 - Metric validation = 0.92.\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1),\n",
    "                                  dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "                        pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "                        metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:37.619340300Z",
     "start_time": "2023-10-10T08:02:28.612974600Z"
    }
   },
   "id": "c4ddf26ee43d0caf"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features      5.000000\nn_estimators    150.000000\nmax_samples      60.000000\nmetric_train      0.958636\nmetric_val        0.929833\nName: 33, dtype: float64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:37.657653200Z",
     "start_time": "2023-10-10T08:02:37.617345200Z"
    }
   },
   "id": "f3c615af9b9b6e4d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model =  model_constructor(max_features = int(best_model['max_features']),\n",
    "                                                  n_estimators = int(best_model['n_estimators']),\n",
    "                                                  max_samples = int(best_model['max_samples']),\n",
    "                                                  random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:37.676226900Z",
     "start_time": "2023-10-10T08:02:37.652525300Z"
    }
   },
   "id": "3a339c2033961c51"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:37.885814Z",
     "start_time": "2023-10-10T08:02:37.661706500Z"
    }
   },
   "id": "b01a72f44944ec4"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.9586 - Metric val = 0.9298 - Metric test = 0.9284\n"
     ]
    }
   ],
   "source": [
    "# print error\n",
    "print('Metric train = %.4f - Metric val = %.4f - Metric test = %.4f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:37.891662600Z",
     "start_time": "2023-10-10T08:02:37.886943500Z"
    }
   },
   "id": "a41082fd2ee92ff0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b06512d582f9c003"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as model_constructor\n",
    "from sklearn.metrics import roc_auc_score as metric"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:38.110451200Z",
     "start_time": "2023-10-10T08:02:37.889453800Z"
    }
   },
   "id": "94649a29c8376f33"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Xgboost\n",
    "n_estimators_values = [1000]\n",
    "learning_rate_values = [1]\n",
    "gamma_values = [1, 10]\n",
    "max_depth_values = [5, 6, 8]\n",
    "min_child_weight_values = [20, 30, 40]\n",
    "subsample_values = [0.1, 1]\n",
    "colsample_bytree_values = [0.1, 1]\n",
    "num_parallel_tree_values = [10]\n",
    "\n",
    "params_grid = {'n_estimators': n_estimators_values,\n",
    "                  'learning_rate': learning_rate_values,\n",
    "                 'gamma': gamma_values,\n",
    "                 'max_depth': max_depth_values,\n",
    "                 'min_child_weight': min_child_weight_values,\n",
    "                 'subsample': subsample_values,\n",
    "                 'colsample_bytree': colsample_bytree_values,\n",
    "                 'num_parallel_tree': num_parallel_tree_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:38.115457700Z",
     "start_time": "2023-10-10T08:02:38.112946100Z"
    }
   },
   "id": "6755d44529122bc8"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "%%capture\n",
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('n_estimators',\n",
    "                                       'learning_rate',\n",
    "                                       'gamma',\n",
    "                                       'max_depth',\n",
    "                                       'min_child_weight',\n",
    "                                       'subsample',\n",
    "                                       'colsample_bytree',\n",
    "                                       'num_parallel_tree',\n",
    "                                       'best_iteration',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for n_estimators in params_grid['n_estimators']:\n",
    "    for learning_rate in params_grid['learning_rate']:\n",
    "        for gamma in params_grid['gamma']:\n",
    "            for max_depth in params_grid['max_depth']:\n",
    "                for min_child_weight in params_grid['min_child_weight']:\n",
    "                    for subsample in params_grid['subsample']:\n",
    "                        for colsample_bytree in params_grid['colsample_bytree']:\n",
    "                            for num_parallel_tree in params_grid['num_parallel_tree']:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                # Print trace\n",
    "                                                print('Iteration = ' + str(num_iter))\n",
    "\n",
    "                                                # [3] Define model\n",
    "                                                model = model_constructor(n_estimators = n_estimators,\n",
    "                                                                      learning_rate = learning_rate,\n",
    "                                                                      gamma = gamma,\n",
    "                                                                      max_depth = max_depth,\n",
    "                                                                      min_child_weight = min_child_weight ,\n",
    "                                                                      subsample = subsample,\n",
    "                                                                      colsample_bytree = colsample_bytree,\n",
    "                                                                      num_parallel_tree = num_parallel_tree,\n",
    "                                                                      early_stopping_rounds = 10,\n",
    "                                                                      eval_metric = \"auc\",\n",
    "                                                                      random_state = 0) # nthread!!!\n",
    "\n",
    "                                                # [4] Train model\n",
    "                                                model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values,\n",
    "                                                          eval_set=[(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'val'].exitus.values)],\n",
    "                                                          verbose = False)\n",
    "                                                best_iteration = model.best_iteration\n",
    "\n",
    "                                                # [5] Predict\n",
    "                                                pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                                                pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                                                # [6] Compute metric\n",
    "                                                metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:, 1])\n",
    "                                                metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:, 1])\n",
    "\n",
    "                                                # print error\n",
    "                                                print('AUC train = %.2f - AUC validation = %.2f.'\n",
    "                                                      % (metric_train, metric_val))\n",
    "\n",
    "                                                # Save iteration results\n",
    "                                                grid_results.loc[num_iter]=[n_estimators,\n",
    "                                                                            learning_rate,\n",
    "                                                                            gamma,\n",
    "                                                                            max_depth,\n",
    "                                                                            min_child_weight,\n",
    "                                                                            subsample,\n",
    "                                                                            colsample_bytree,\n",
    "                                                                            num_parallel_tree,\n",
    "                                                                            best_iteration,\n",
    "                                                                            metric_train,\n",
    "                                                                            metric_val]\n",
    "                                                num_iter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.825466800Z",
     "start_time": "2023-10-10T08:02:38.116459Z"
    }
   },
   "id": "fa0b192d5130ed46"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "n_estimators         1000.000000\nlearning_rate           1.000000\ngamma                  10.000000\nmax_depth               5.000000\nmin_child_weight       20.000000\nsubsample               1.000000\ncolsample_bytree        0.100000\nnum_parallel_tree      10.000000\nbest_iteration          1.000000\nmetric_train            0.918223\nmetric_val              0.907949\nName: 39, dtype: float64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_xgb = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model_xgb = grid_results_xgb.iloc[0]\n",
    "best_model_xgb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.832498800Z",
     "start_time": "2023-10-10T08:02:41.825466800Z"
    }
   },
   "id": "c258ebe4007c46e0"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# [3] define model\n",
    "model = model_constructor(n_estimators = int(best_model_xgb.best_iteration),\n",
    "                          learning_rate = best_model_xgb.learning_rate,\n",
    "                          gamma = best_model_xgb.gamma,\n",
    "                          max_depth = int(best_model_xgb.max_depth),\n",
    "                          min_child_weight = best_model_xgb.min_child_weight,\n",
    "                          subsample = best_model_xgb.subsample,\n",
    "                          colsample_bytree = best_model_xgb.colsample_bytree,\n",
    "                          num_parallel_tree = int(best_model_xgb.num_parallel_tree),\n",
    "                          random_state = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.848822200Z",
     "start_time": "2023-10-10T08:02:41.836011900Z"
    }
   },
   "id": "e503a2e6c3766e14"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "%%capture\n",
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] != 'test'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] != 'test'].exitus.values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.888879900Z",
     "start_time": "2023-10-10T08:02:41.840301700Z"
    }
   },
   "id": "f9480bca124b9b40"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "%%capture\n",
    "pred_train_p = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_val_p = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1))\n",
    "pred_test_p = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.908119700Z",
     "start_time": "2023-10-10T08:02:41.875358600Z"
    }
   },
   "id": "fc25a711c6e0bd8b"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.9164 - Metric val = 0.9324 - Metric test = 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "auc_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train_p[:,1])\n",
    "auc_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val_p[:,1])\n",
    "auc_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test_p[:,1])\n",
    "\n",
    "# print error\n",
    "print('Metric train = %.4f - Metric val = %.4f - Metric test = %.4f'\n",
    "      % (auc_train, auc_val, auc_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.932137700Z",
     "start_time": "2023-10-10T08:02:41.897365400Z"
    }
   },
   "id": "878157cbee14a4fa"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results\n",
      "Metric train = 0.8382 - Metric val = 0.8291 - Metric test = 0.9284\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest Results')\n",
    "print('Metric train = %.4f - Metric val = %.4f - Metric test = %.4f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:02:41.975736900Z",
     "start_time": "2023-10-10T08:02:41.909128600Z"
    }
   },
   "id": "b3da6fbbbcf087c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVM Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "118e75589dab6152"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC as model_constructor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:03:24.603839100Z",
     "start_time": "2023-10-10T08:03:24.587079500Z"
    }
   },
   "id": "1646883e5709c2e2"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get Cherksassky parameters --> This is optional!!!\n",
    "d = dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1).shape[1]\n",
    "m = np.mean(dat[dat['dataset']  == 'train'].exitus.values)\n",
    "s = np.std(dat[dat['dataset']  == 'train'].exitus.values)\n",
    "\n",
    "C_cherk = np.max([np.abs(m + 3*s),np.abs(m - 3*s)])\n",
    "gamma_cherk = np.power(0.2, 1/d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:04:14.697549500Z",
     "start_time": "2023-10-10T08:04:14.667468100Z"
    }
   },
   "id": "a8d4cccfa4c232ac"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# SVM\n",
    "C_values = [0.4, 0.5, 0.6]\n",
    "gamma_values = [0.9, 1]\n",
    "\n",
    "params_grid = {'C': C_values,\n",
    "               'gamma': gamma_values}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:09:45.440418500Z",
     "start_time": "2023-10-10T08:09:45.405469400Z"
    }
   },
   "id": "60be4a3d45fa8e5e"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n",
      "Iteration = 2\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n",
      "Iteration = 3\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n",
      "Iteration = 4\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n",
      "Iteration = 5\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n",
      "Iteration = 6\n",
      "AUC train = 0.00 - AUC validation = 0.43.\n"
     ]
    }
   ],
   "source": [
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('C',\n",
    "                                       'gamma',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for C in params_grid['C']:\n",
    "    for gamma in params_grid['gamma']:\n",
    "\n",
    "                    # Print trace\n",
    "                    print('Iteration = ' + str(num_iter))\n",
    "\n",
    "                    # [3] Define model\n",
    "                    model = model_constructor(C = C,\n",
    "                                              gamma = gamma,\n",
    "                                              probability = True,\n",
    "                                              random_state = 0) # Probability = True!!!\n",
    "\n",
    "                    # [4] Train model\n",
    "                    model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset']  == 'train'].exitus.values)\n",
    "\n",
    "                    # [5] Predict\n",
    "                    pred_train = model.predict_proba(dat[dat['dataset']  == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "                    pred_val = model.predict_proba(dat[dat['dataset']  == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict_proba!\n",
    "\n",
    "                    # [6] Compute metric\n",
    "                    metric_train = metric(dat[dat['dataset']  == 'train'].exitus.values, pred_train[:,1])\n",
    "                    metric_val = metric(dat[dat['dataset']  == 'val'].exitus.values, pred_val[:,1])\n",
    "\n",
    "                    # print error\n",
    "                    print('AUC train = %.2f - AUC validation = %.2f.'\n",
    "                          % (metric_train, metric_val))\n",
    "\n",
    "                    # Save iteration results\n",
    "                    grid_results.loc[num_iter]=[C,\n",
    "                                                gamma,\n",
    "                                                metric_train,\n",
    "                                                metric_val]\n",
    "                    num_iter += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:09:55.290725100Z",
     "start_time": "2023-10-10T08:09:47.326616900Z"
    }
   },
   "id": "32cd9226f12db8ca"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "C               0.594870\ngamma           0.929456\nmetric_train    0.000000\nmetric_val      0.429601\nName: 4, dtype: float64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results_svm = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, False])\n",
    "best_model_svm = grid_results_svm.iloc[0]\n",
    "best_model_svm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:05:17.368093900Z",
     "start_time": "2023-10-10T08:05:17.326912300Z"
    }
   },
   "id": "df71cb804a044c51"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 1.00 - Metric val = 1.00 - Metric test = 0.67\n"
     ]
    }
   ],
   "source": [
    "# [3] Define model\n",
    "model = model_constructor(C = best_model_svm.C,\n",
    "                           gamma = best_model_svm.gamma,\n",
    "                           probability = True,\n",
    "                           random_state = 0) # Probability = True!!!\n",
    "\n",
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] != 'test'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] != 'test'].exitus.values)\n",
    "\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])\n",
    "\n",
    "# print error\n",
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-10T08:05:51.319107100Z",
     "start_time": "2023-10-10T08:05:26.475963300Z"
    }
   },
   "id": "e6b801b779cc7a21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
