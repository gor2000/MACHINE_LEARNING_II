{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "zAIy5xxhR1jq",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:29:54.718624700Z",
     "start_time": "2023-09-21T10:29:54.701972600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKjW1IzZR1jr"
   },
   "source": [
    "# Random Forest Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYLRg47NR1jt"
   },
   "source": [
    "In this exercise you will have to implement code in the section *Fill with Your Code* to create a random forest to predict the target column of the Breast cancer dataset.\n",
    "\n",
    "The code that is already written in this notebook **CANNOT BE CHANGED**. You can only add code in the *Fill with Your Code* section.\n",
    "\n",
    "You must achieve in the last cell of this notebook an **F1-score over test of at least 0.35**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TXeFiq2R1ju"
   },
   "source": [
    "## Key Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g8m-6BLHR1ju",
    "ExecuteTime": {
     "end_time": "2023-09-21T09:46:02.437435500Z",
     "start_time": "2023-09-21T09:46:02.422988900Z"
    }
   },
   "outputs": [],
   "source": [
    "# [1] Import model\n",
    "from sklearn.ensemble import RandomForestClassifier as model_constructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HksBrd2FR1jv"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URB9STDRR1jv"
   },
   "source": [
    "You already know it is iris..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "SQBkGWWER1jw",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:29:57.106452100Z",
     "start_time": "2023-09-21T10:29:57.010038100Z"
    }
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../data/healthcare_missing.csv', sep = \",\")\n",
    "y = dat['exitus']\n",
    "X = dat.drop(['exitus'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KzdRRqZKR1jx",
    "ExecuteTime": {
     "end_time": "2023-09-21T09:53:22.259849700Z",
     "start_time": "2023-09-21T09:53:22.236714900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          date  severity  mortality_ratio    age  num_proc  ambulatory  \\\n0      2016-01         4         0.408730  12596        21           0   \n1      2016-01         4         0.306931  20973        22           0   \n2      2016-01         4         0.278481  19611        19           0   \n3      2016-01         3         0.150289  13583        22           0   \n4      2016-01         1         0.016573  18042         2           0   \n...        ...       ...              ...    ...       ...         ...   \n32701  2016-12         2         0.028365  23619         2           0   \n32702  2016-12         1         0.000606   3935         1           0   \n32703  2016-12         2         0.040452  30163         4           0   \n32704  2016-12         2         0.000000  29012         4           0   \n32705  2016-12         1         0.000000  13244         1           1   \n\n       origin  expected_length tip_grd  tip_adm  exitus  \n0           1              151       Q      1.0       0  \n1           1               99       Q      1.0       0  \n2           1               87       Q      1.0       0  \n3           1              100       Q      1.0       0  \n4           1               44       Q      1.0       0  \n...       ...              ...     ...      ...     ...  \n32701       1                2       M      1.0       0  \n32702       1                2       M      1.0       0  \n32703       1                2       M      1.0       0  \n32704       1                0       M      1.0       0  \n32705       1                0       Q      1.0       0  \n\n[32706 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01</td>\n      <td>4</td>\n      <td>0.408730</td>\n      <td>12596</td>\n      <td>21</td>\n      <td>0</td>\n      <td>1</td>\n      <td>151</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01</td>\n      <td>4</td>\n      <td>0.306931</td>\n      <td>20973</td>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>99</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>4</td>\n      <td>0.278481</td>\n      <td>19611</td>\n      <td>19</td>\n      <td>0</td>\n      <td>1</td>\n      <td>87</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>3</td>\n      <td>0.150289</td>\n      <td>13583</td>\n      <td>22</td>\n      <td>0</td>\n      <td>1</td>\n      <td>100</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01</td>\n      <td>1</td>\n      <td>0.016573</td>\n      <td>18042</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>44</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>2016-12</td>\n      <td>2</td>\n      <td>0.028365</td>\n      <td>23619</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>2016-12</td>\n      <td>1</td>\n      <td>0.000606</td>\n      <td>3935</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>2016-12</td>\n      <td>2</td>\n      <td>0.040452</td>\n      <td>30163</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>2016-12</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>29012</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>2016-12</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>13244</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows Ã— 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['date', 'severity', 'mortality_ratio', 'age', 'num_proc', 'ambulatory',\n       'origin', 'expected_length', 'tip_grd', 'tip_adm', 'exitus'],\n      dtype='object')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T09:54:42.007792100Z",
     "start_time": "2023-09-21T09:54:41.962978700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2S3smkmR1jx"
   },
   "source": [
    "## Fill with Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "origin\n1.0    9095\n2.0    2268\n4.0     230\n8.0     208\n3.0     185\n6.0     165\n9.0      95\nName: count, dtype: int64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "dat['origin'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:07:34.626564700Z",
     "start_time": "2023-09-21T10:07:34.573319600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'severity', 'origin', 'ambulatory', 'tip_grd', 'tip_adm']\n",
      "['age', 'mortality_ratio', 'num_proc', 'expected_length']\n"
     ]
    }
   ],
   "source": [
    "categorical_vars = ['date', 'severity', 'origin', 'ambulatory', 'tip_grd', 'tip_adm']\n",
    "non_categorical_vars = list(set(X.columns) - set(categorical_vars))\n",
    "numerical_variables = list(set(dat.columns) - set(categorical_vars) - {'dataset', 'date', 'exitus'})\n",
    "print(categorical_vars)\n",
    "print(numerical_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:29:59.366375500Z",
     "start_time": "2023-09-21T10:29:59.348916800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# 3 defining the model\n",
    "ohe = OneHotEncoder(sparse_output = False, drop='first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(X[categorical_vars])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(X[categorical_vars]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "\n",
    "# Combine numerical and categorical\n",
    "dat = pd.concat((X[non_categorical_vars], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:30:00.335180900Z",
     "start_time": "2023-09-21T10:30:00.247209900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "age                 True\nmortality_ratio     True\nnum_proc            True\nexpected_length     True\ndate_2016-02       False\ndate_2016-03       False\ndate_2016-04       False\ndate_2016-05       False\ndate_2016-06       False\ndate_2016-07       False\ndate_2016-08       False\ndate_2016-09       False\ndate_2016-10       False\ndate_2016-11       False\ndate_2016-12       False\nseverity_2.0       False\nseverity_3.0       False\nseverity_4.0       False\nseverity_nan       False\norigin_2.0         False\norigin_3.0         False\norigin_4.0         False\norigin_6.0         False\norigin_8.0         False\norigin_9.0         False\norigin_nan         False\nambulatory_1.0     False\nambulatory_nan     False\ntip_grd_Q          False\ntip_grd_nan        False\ntip_adm_2.0        False\ntip_adm_3.0        False\ntip_adm_nan        False\ndtype: bool"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill missing values\n",
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:26:10.071175800Z",
     "start_time": "2023-09-21T10:26:10.055709600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from fancyimpute import IterativeImputer as MICE # pip install fancyimpute\n",
    "numerical_vars = list(set(dat.columns) - {'exitus', 'dataset'})\n",
    "model = MICE()\n",
    "dat[numerical_vars] = model.fit_transform(dat[numerical_vars])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:30:09.512027100Z",
     "start_time": "2023-09-21T10:30:03.131846100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "age                False\nmortality_ratio    False\nnum_proc           False\nexpected_length    False\ndate_2016-02       False\ndate_2016-03       False\ndate_2016-04       False\ndate_2016-05       False\ndate_2016-06       False\ndate_2016-07       False\ndate_2016-08       False\ndate_2016-09       False\ndate_2016-10       False\ndate_2016-11       False\ndate_2016-12       False\nseverity_2.0       False\nseverity_3.0       False\nseverity_4.0       False\nseverity_nan       False\norigin_2.0         False\norigin_3.0         False\norigin_4.0         False\norigin_6.0         False\norigin_8.0         False\norigin_9.0         False\norigin_nan         False\nambulatory_1.0     False\nambulatory_nan     False\ntip_grd_Q          False\ntip_grd_nan        False\ntip_adm_2.0        False\ntip_adm_3.0        False\ntip_adm_nan        False\ndtype: bool"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isna().any()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:26:19.253926900Z",
     "start_time": "2023-09-21T10:26:19.238555100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "perc_values = [0.7, 0.15, 0.15]\n",
    "X_train, X_valtest, y_train, y_valtest = train_test_split(dat, y, stratify = y, test_size=perc_values[1] + perc_values[2], random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_valtest, y_valtest, stratify = y_valtest, test_size= perc_values[2] / (perc_values[1] + perc_values[2]), random_state=1)"
   ],
   "metadata": {
    "id": "WDmM6oSRSC9-",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:30:13.039713300Z",
     "start_time": "2023-09-21T10:30:12.967644400Z"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "caChYdK1R1j0",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:35:14.082027100Z",
     "start_time": "2023-09-21T10:30:14.388580400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 2\n",
      "Metric train = 0.02 - Metric validation = 0.02.\n",
      "Iteracion = 3\n",
      "Metric train = 0.08 - Metric validation = 0.08.\n",
      "Iteracion = 4\n",
      "Metric train = 0.92 - Metric validation = 0.21.\n",
      "Iteracion = 5\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 6\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 7\n",
      "Metric train = 0.02 - Metric validation = 0.01.\n",
      "Iteracion = 8\n",
      "Metric train = 1.00 - Metric validation = 0.20.\n",
      "Iteracion = 9\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 10\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 11\n",
      "Metric train = 0.01 - Metric validation = 0.01.\n",
      "Iteracion = 12\n",
      "Metric train = 1.00 - Metric validation = 0.20.\n",
      "Iteracion = 13\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 14\n",
      "Metric train = 0.01 - Metric validation = 0.01.\n",
      "Iteracion = 15\n",
      "Metric train = 0.20 - Metric validation = 0.20.\n",
      "Iteracion = 16\n",
      "Metric train = 0.94 - Metric validation = 0.30.\n",
      "Iteracion = 17\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 18\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 19\n",
      "Metric train = 0.08 - Metric validation = 0.07.\n",
      "Iteracion = 20\n",
      "Metric train = 1.00 - Metric validation = 0.28.\n",
      "Iteracion = 21\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 22\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 23\n",
      "Metric train = 0.08 - Metric validation = 0.07.\n",
      "Iteracion = 24\n",
      "Metric train = 1.00 - Metric validation = 0.30.\n",
      "Iteracion = 25\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 26\n",
      "Metric train = 0.02 - Metric validation = 0.01.\n",
      "Iteracion = 27\n",
      "Metric train = 0.21 - Metric validation = 0.21.\n",
      "Iteracion = 28\n",
      "Metric train = 0.93 - Metric validation = 0.29.\n",
      "Iteracion = 29\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 30\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 31\n",
      "Metric train = 0.22 - Metric validation = 0.23.\n",
      "Iteracion = 32\n",
      "Metric train = 1.00 - Metric validation = 0.33.\n",
      "Iteracion = 33\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 34\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 35\n",
      "Metric train = 0.19 - Metric validation = 0.21.\n",
      "Iteracion = 36\n",
      "Metric train = 1.00 - Metric validation = 0.31.\n",
      "Iteracion = 37\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 38\n",
      "Metric train = 0.21 - Metric validation = 0.28.\n",
      "Iteracion = 39\n",
      "Metric train = 0.25 - Metric validation = 0.20.\n",
      "Iteracion = 40\n",
      "Metric train = 0.93 - Metric validation = 0.32.\n",
      "Iteracion = 41\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 42\n",
      "Metric train = 0.06 - Metric validation = 0.04.\n",
      "Iteracion = 43\n",
      "Metric train = 0.28 - Metric validation = 0.25.\n",
      "Iteracion = 44\n",
      "Metric train = 1.00 - Metric validation = 0.34.\n",
      "Iteracion = 45\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 46\n",
      "Metric train = 0.05 - Metric validation = 0.05.\n",
      "Iteracion = 47\n",
      "Metric train = 0.29 - Metric validation = 0.29.\n",
      "Iteracion = 48\n",
      "Metric train = 1.00 - Metric validation = 0.35.\n",
      "Iteracion = 49\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 50\n",
      "Metric train = 0.21 - Metric validation = 0.28.\n",
      "Iteracion = 51\n",
      "Metric train = 0.25 - Metric validation = 0.20.\n",
      "Iteracion = 52\n",
      "Metric train = 0.93 - Metric validation = 0.32.\n",
      "Iteracion = 53\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 54\n",
      "Metric train = 0.06 - Metric validation = 0.04.\n",
      "Iteracion = 55\n",
      "Metric train = 0.28 - Metric validation = 0.25.\n",
      "Iteracion = 56\n",
      "Metric train = 1.00 - Metric validation = 0.34.\n",
      "Iteracion = 57\n",
      "Metric train = 0.00 - Metric validation = 0.00.\n",
      "Iteracion = 58\n",
      "Metric train = 0.05 - Metric validation = 0.05.\n",
      "Iteracion = 59\n",
      "Metric train = 0.29 - Metric validation = 0.29.\n",
      "Iteracion = 60\n",
      "Metric train = 1.00 - Metric validation = 0.35.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor\n",
    "from sklearn.metrics import f1_score as metric\n",
    "\n",
    "# Random Forest\n",
    "n_estimators_values = [10, 100, 1000]\n",
    "max_features_values = [2, 5, 10, 50, 100]\n",
    "max_samples_values = [10,100, 1000, X_train.shape[0]]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}\n",
    "\n",
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict(X_train) # predict!\n",
    "                        pred_val = model.predict(X_val) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(y_train, pred_train)\n",
    "                        metric_val = metric(y_val, pred_val)\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features       50.000000\nn_estimators     1000.000000\nmax_samples     22894.000000\nmetric_train        1.000000\nmetric_val          0.345865\nName: 48, dtype: float64"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, True])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T10:36:02.782331400Z",
     "start_time": "2023-09-21T10:36:02.741772700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOUDcDL5R1j1"
   },
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpwnIwIAR1j1"
   },
   "source": [
    "Validation has served its purpose, let's combine it with train to get more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "E1ReuZUUR1j2",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:36:27.376879600Z",
     "start_time": "2023-09-21T10:36:27.356335700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old train data size = (27800, 33)\n",
      "Old train target size = (27800,)\n",
      "New train data size = (32706, 33)\n",
      "New train target size = (32706,)\n"
     ]
    }
   ],
   "source": [
    "print('Old train data size = ' + str(X_train.shape))\n",
    "print('Old train target size = ' + str(y_train.shape))\n",
    "\n",
    "# Combine train and validaciÃ³n\n",
    "X_train = np.concatenate((X_train, X_val), axis = 0)\n",
    "y_train = np.concatenate((y_train, y_val), axis = 0)\n",
    "\n",
    "print('New train data size = ' + str(X_train.shape))\n",
    "print('New train target size = ' + str(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "Etu_FMMkR1j2",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:39:08.937485400Z",
     "start_time": "2023-09-21T10:37:48.280047800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\IE\\SECOND TERM\\MLII\\venv\\Lib\\site-packages\\sklearn\\base.py:457: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# [3] Define model\n",
    "model = model_constructor(criterion = 'gini',\n",
    "                          max_depth = None,\n",
    "                          min_samples_split = 2,\n",
    "                          min_samples_leaf = 1,\n",
    "                          max_features = int(best_model.max_features),\n",
    "                          n_estimators =  int(best_model.n_estimators),\n",
    "                          max_samples = int(best_model.max_samples),\n",
    "                          random_state = 0) # Use same random_state as in training!!!\n",
    "\n",
    "# [4] Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict(X_train)\n",
    "pred_test = model.predict(X_test)\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(y_train, pred_train)\n",
    "metric_test = metric(y_test, pred_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lp34PgirR1j2",
    "outputId": "c0ce1bf9-ca7c-48c4-ec84-e803c7b079ea",
    "ExecuteTime": {
     "end_time": "2023-09-21T10:39:20.194835100Z",
     "start_time": "2023-09-21T10:39:20.178285800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC train = 0.99 - AUC test = 0.28\n"
     ]
    }
   ],
   "source": [
    "# print error\n",
    "print('AUC train = %.2f - AUC test = %.2f'\n",
    "      % (metric_train, metric_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
