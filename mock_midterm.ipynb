{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "_OKK2VwBbP81",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.384732Z",
     "start_time": "2023-09-19T20:49:24.305065700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Mock Midterm Exercise"
   ],
   "metadata": {
    "id": "VoFYQVQ0bVCN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise you will have to implement code in the sections inside *Fill with Your Code* (*Load Data*, *Data Preprocessing* and *Create Model*) create a model to predict the column *exitus* in the dataset given. The dataset is already split into train, validation, and test subsets. To see to which subset belong each observation, you need to check the *dataset* column.\n",
    "\n",
    "The code that is already written in this notebook **CANNOT BE CHANGED**. You can only add code in the *Fill with Your Code* section.\n",
    "\n",
    "You must achieve in the last cell of this notebook an **AUC over test of at least 0.93**."
   ],
   "metadata": {
    "id": "xdYg4_U3bYH8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fill With Your Code"
   ],
   "metadata": {
    "id": "_lpuKCkfb9do"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [1] Load Data"
   ],
   "metadata": {
    "id": "66HBtc2Cbpm_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dat = pd.read_csv('data/dat.csv', sep = \",\")"
   ],
   "metadata": {
    "id": "EtxuaDPHbWj1",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.914795900Z",
     "start_time": "2023-09-19T20:49:24.349622600Z"
    }
   },
   "execution_count": 133,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dat"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "Qq_JqH9bev9L",
    "outputId": "95b4918a-7f25-4969-9592-bc4d6b7649bd",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.929306Z",
     "start_time": "2023-09-19T20:49:24.381723400Z"
    }
   },
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "          date  severity  mortality_ratio      age  num_proc  ambulatory  \\\n0      2016-01       NaN         0.408730  12596.0      21.0         0.0   \n1      2016-01       NaN         0.306931  20973.0      22.0         NaN   \n2      2016-01       4.0         0.278481  19611.0      19.0         NaN   \n3      2016-01       3.0         0.150289  13583.0      22.0         NaN   \n4      2016-01       1.0         0.016573  18042.0       2.0         NaN   \n...        ...       ...              ...      ...       ...         ...   \n32701  2016-12       2.0         0.028365  23619.0       2.0         NaN   \n32702  2016-12       1.0         0.000606   3935.0       1.0         NaN   \n32703  2016-12       NaN         0.040452  30163.0       4.0         NaN   \n32704  2016-12       NaN         0.000000  29012.0       4.0         NaN   \n32705  2016-12       NaN         0.000000  13244.0       1.0         NaN   \n\n       origin  expected_length tip_grd  tip_adm  exitus dataset  \n0         NaN            151.0       Q      1.0       0   train  \n1         NaN             99.0       Q      1.0       0   train  \n2         NaN             87.0     NaN      1.0       0   train  \n3         NaN            100.0       Q      NaN       0   train  \n4         NaN             44.0       Q      1.0       0   train  \n...       ...              ...     ...      ...     ...     ...  \n32701     NaN              2.0     NaN      1.0       0    test  \n32702     1.0              2.0       M      1.0       0    test  \n32703     NaN              2.0       M      NaN       0    test  \n32704     NaN              0.0     NaN      1.0       0    test  \n32705     NaN              0.0       Q      1.0       0    test  \n\n[32706 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>severity</th>\n      <th>mortality_ratio</th>\n      <th>age</th>\n      <th>num_proc</th>\n      <th>ambulatory</th>\n      <th>origin</th>\n      <th>expected_length</th>\n      <th>tip_grd</th>\n      <th>tip_adm</th>\n      <th>exitus</th>\n      <th>dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.408730</td>\n      <td>12596.0</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>151.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2016-01</td>\n      <td>NaN</td>\n      <td>0.306931</td>\n      <td>20973.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>99.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2016-01</td>\n      <td>4.0</td>\n      <td>0.278481</td>\n      <td>19611.0</td>\n      <td>19.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>87.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2016-01</td>\n      <td>3.0</td>\n      <td>0.150289</td>\n      <td>13583.0</td>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>100.0</td>\n      <td>Q</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2016-01</td>\n      <td>1.0</td>\n      <td>0.016573</td>\n      <td>18042.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>44.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>23619.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>2016-12</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>3935.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.040452</td>\n      <td>30163.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>M</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>29012.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>2016-12</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>13244.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Q</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [2]  Data Preprocessing"
   ],
   "metadata": {
    "id": "bALdZkw9dzzv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dat['severity'].value_counts()"
   ],
   "metadata": {
    "id": "zBr3_3ZnrvIo",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.929306Z",
     "start_time": "2023-09-19T20:49:24.395254100Z"
    }
   },
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "severity\n1.0    7721\n2.0    1912\n3.0    1767\n4.0     672\nName: count, dtype: int64"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "origin\n1.0    9095\n2.0    2268\n4.0     230\n8.0     208\n3.0     185\n6.0     165\n9.0      95\nName: count, dtype: int64"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['origin'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.930310500Z",
     "start_time": "2023-09-19T20:49:24.408867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
      "['mortality_ratio', 'age', 'num_proc', 'expected_length']\n"
     ]
    }
   ],
   "source": [
    "categorical_variables = ['severity', 'ambulatory', 'origin', 'tip_grd', 'tip_adm']\n",
    "non_categorical_variables = list(set(dat.columns) - set(categorical_variables))\n",
    "numerical_variables = list(set(dat.columns) - set(categorical_variables) - {'dataset', 'date', 'exitus'})\n",
    "print(categorical_variables)\n",
    "print(numerical_variables)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.933821500Z",
     "start_time": "2023-09-19T20:49:24.424539500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "date                0.000000\nseverity           63.089341\nmortality_ratio     6.934507\nage                 1.296398\nnum_proc            4.127683\nambulatory         94.010273\norigin             62.557329\nexpected_length     5.726778\ntip_grd            41.631505\ntip_adm            18.617379\nexitus              0.000000\ndataset             0.000000\ndtype: float64"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values\n",
    "dat.apply(lambda x: 100*np.sum(x.isna())/len(x))\n",
    "\n",
    "# The percentage is high, so I am not going to remove the rows"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.939820800Z",
     "start_time": "2023-09-19T20:49:24.435363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "dat[categorical_variables] = dat[categorical_variables].fillna('UNKNOWN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.939820800Z",
     "start_time": "2023-09-19T20:49:24.452849400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "date               0.000000\nseverity           0.000000\nmortality_ratio    6.934507\nage                1.296398\nnum_proc           4.127683\nambulatory         0.000000\norigin             0.000000\nexpected_length    5.726778\ntip_grd            0.000000\ntip_adm            0.000000\nexitus             0.000000\ndataset            0.000000\ndtype: float64"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.apply(lambda x: 100*np.sum(x.isna())/len(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.939820800Z",
     "start_time": "2023-09-19T20:49:24.470540300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "dat[numerical_variables] = dat[numerical_variables].apply(lambda x: x.fillna(x.median()), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.939820800Z",
     "start_time": "2023-09-19T20:49:24.486954700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "date               0.0\nseverity           0.0\nmortality_ratio    0.0\nage                0.0\nnum_proc           0.0\nambulatory         0.0\norigin             0.0\nexpected_length    0.0\ntip_grd            0.0\ntip_adm            0.0\nexitus             0.0\ndataset            0.0\ndtype: float64"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.apply(lambda x: 100*np.sum(x.isna())/len(x))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.975440100Z",
     "start_time": "2023-09-19T20:49:24.532436300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "dat[categorical_variables] = dat[categorical_variables].astype(str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.975440100Z",
     "start_time": "2023-09-19T20:49:24.582366Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# 3 defining the model\n",
    "ohe = OneHotEncoder(sparse_output = False, drop = 'first')\n",
    "\n",
    "# 4) Training model\n",
    "ohe.fit(dat[categorical_variables])\n",
    "\n",
    "# 5) Predicting\n",
    "dat_ohe = pd.DataFrame(ohe.fit_transform(dat[categorical_variables]))\n",
    "\n",
    "# Optional\n",
    "dat_ohe.columns = ohe.get_feature_names_out()\n",
    "\n",
    "# Combine numerical and categorical\n",
    "dat = pd.concat((dat[non_categorical_variables], dat_ohe), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.976945500Z",
     "start_time": "2023-09-19T20:49:24.601309600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "           age dataset  exitus     date  expected_length  num_proc  \\\n0      12596.0   train       0  2016-01            151.0      21.0   \n1      20973.0   train       0  2016-01             99.0      22.0   \n2      19611.0   train       0  2016-01             87.0      19.0   \n3      13583.0   train       0  2016-01            100.0      22.0   \n4      18042.0   train       0  2016-01             44.0       2.0   \n...        ...     ...     ...      ...              ...       ...   \n32701  23619.0    test       0  2016-12              2.0       2.0   \n32702   3935.0    test       0  2016-12              2.0       1.0   \n32703  30163.0    test       0  2016-12              2.0       4.0   \n32704  29012.0    test       0  2016-12              0.0       4.0   \n32705  13244.0    test       0  2016-12              0.0       1.0   \n\n       mortality_ratio  severity_2.0  severity_3.0  severity_4.0  ...  \\\n0             0.408730           0.0           0.0           0.0  ...   \n1             0.306931           0.0           0.0           0.0  ...   \n2             0.278481           0.0           0.0           1.0  ...   \n3             0.150289           0.0           1.0           0.0  ...   \n4             0.016573           0.0           0.0           0.0  ...   \n...                ...           ...           ...           ...  ...   \n32701         0.028365           1.0           0.0           0.0  ...   \n32702         0.000606           0.0           0.0           0.0  ...   \n32703         0.040452           0.0           0.0           0.0  ...   \n32704         0.000000           0.0           0.0           0.0  ...   \n32705         0.000000           0.0           0.0           0.0  ...   \n\n       origin_4.0  origin_6.0  origin_8.0  origin_9.0  origin_UNKNOWN  \\\n0             0.0         0.0         0.0         0.0             1.0   \n1             0.0         0.0         0.0         0.0             1.0   \n2             0.0         0.0         0.0         0.0             1.0   \n3             0.0         0.0         0.0         0.0             1.0   \n4             0.0         0.0         0.0         0.0             1.0   \n...           ...         ...         ...         ...             ...   \n32701         0.0         0.0         0.0         0.0             1.0   \n32702         0.0         0.0         0.0         0.0             0.0   \n32703         0.0         0.0         0.0         0.0             1.0   \n32704         0.0         0.0         0.0         0.0             1.0   \n32705         0.0         0.0         0.0         0.0             1.0   \n\n       tip_grd_Q  tip_grd_UNKNOWN  tip_adm_2.0  tip_adm_3.0  tip_adm_UNKNOWN  \n0            1.0              0.0          0.0          0.0              0.0  \n1            1.0              0.0          0.0          0.0              0.0  \n2            0.0              1.0          0.0          0.0              0.0  \n3            1.0              0.0          0.0          0.0              1.0  \n4            1.0              0.0          0.0          0.0              0.0  \n...          ...              ...          ...          ...              ...  \n32701        0.0              1.0          0.0          0.0              0.0  \n32702        0.0              0.0          0.0          0.0              0.0  \n32703        0.0              0.0          0.0          0.0              1.0  \n32704        0.0              1.0          0.0          0.0              0.0  \n32705        1.0              0.0          0.0          0.0              0.0  \n\n[32706 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>dataset</th>\n      <th>exitus</th>\n      <th>date</th>\n      <th>expected_length</th>\n      <th>num_proc</th>\n      <th>mortality_ratio</th>\n      <th>severity_2.0</th>\n      <th>severity_3.0</th>\n      <th>severity_4.0</th>\n      <th>...</th>\n      <th>origin_4.0</th>\n      <th>origin_6.0</th>\n      <th>origin_8.0</th>\n      <th>origin_9.0</th>\n      <th>origin_UNKNOWN</th>\n      <th>tip_grd_Q</th>\n      <th>tip_grd_UNKNOWN</th>\n      <th>tip_adm_2.0</th>\n      <th>tip_adm_3.0</th>\n      <th>tip_adm_UNKNOWN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12596.0</td>\n      <td>train</td>\n      <td>0</td>\n      <td>2016-01</td>\n      <td>151.0</td>\n      <td>21.0</td>\n      <td>0.408730</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20973.0</td>\n      <td>train</td>\n      <td>0</td>\n      <td>2016-01</td>\n      <td>99.0</td>\n      <td>22.0</td>\n      <td>0.306931</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19611.0</td>\n      <td>train</td>\n      <td>0</td>\n      <td>2016-01</td>\n      <td>87.0</td>\n      <td>19.0</td>\n      <td>0.278481</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13583.0</td>\n      <td>train</td>\n      <td>0</td>\n      <td>2016-01</td>\n      <td>100.0</td>\n      <td>22.0</td>\n      <td>0.150289</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18042.0</td>\n      <td>train</td>\n      <td>0</td>\n      <td>2016-01</td>\n      <td>44.0</td>\n      <td>2.0</td>\n      <td>0.016573</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32701</th>\n      <td>23619.0</td>\n      <td>test</td>\n      <td>0</td>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.028365</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32702</th>\n      <td>3935.0</td>\n      <td>test</td>\n      <td>0</td>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.000606</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32703</th>\n      <td>30163.0</td>\n      <td>test</td>\n      <td>0</td>\n      <td>2016-12</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>0.040452</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>32704</th>\n      <td>29012.0</td>\n      <td>test</td>\n      <td>0</td>\n      <td>2016-12</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>32705</th>\n      <td>13244.0</td>\n      <td>test</td>\n      <td>0</td>\n      <td>2016-12</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>32706 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.977956600Z",
     "start_time": "2023-09-19T20:49:24.655704400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "            count\nexitus           \n0       96.159726\n1        3.840274",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>96.159726</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.840274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*dat.groupby(['exitus'])['exitus'].agg(['count'])/dat.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.978956100Z",
     "start_time": "2023-09-19T20:49:24.688361900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "        count\nexitus       \n0        50.0\n1        50.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>exitus</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Initializing SMOTE object\n",
    "sm = SMOTE(sampling_strategy = 1.0,\n",
    "           random_state = 0,\n",
    "           k_neighbors = 5)\n",
    "\n",
    "# Performing oversampling\n",
    "X_res, y_res = sm.fit_resample(dat.drop(['exitus', 'date', 'dataset'], axis = 1), dat['exitus'])\n",
    "\n",
    "# Concatenating the oversampled features and labels into a new DataFrame\n",
    "dat = pd.concat([X_res, y_res, dat['dataset'], dat['date']], axis = 1)\n",
    "\n",
    "# Checking the class distribution after SMOTE\n",
    "100 * dat.groupby(['exitus'])['exitus'].agg(['count']) / dat.shape[0]\n",
    "\n",
    "# only with train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.979956800Z",
     "start_time": "2023-09-19T20:49:24.698745200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "                age  expected_length   num_proc  mortality_ratio  \\\n0      12596.000000       151.000000  21.000000         0.408730   \n1      20973.000000        99.000000  22.000000         0.306931   \n2      19611.000000        87.000000  19.000000         0.278481   \n3      13583.000000       100.000000  22.000000         0.150289   \n4      18042.000000        44.000000   2.000000         0.016573   \n...             ...              ...        ...              ...   \n62895  22177.756113        13.554858   8.621943         0.091532   \n62896  25076.828341         5.935628   5.978543         0.532906   \n62897  31820.349352        13.280959   7.116451         0.318403   \n62898  33433.609957         7.804978   4.451245         0.041255   \n62899  32293.045267         5.877493   6.251662         0.153552   \n\n       severity_2.0  severity_3.0  severity_4.0  severity_UNKNOWN  \\\n0          0.000000      0.000000      0.000000          1.000000   \n1          0.000000      0.000000      0.000000          1.000000   \n2          0.000000      0.000000      1.000000          0.000000   \n3          0.000000      1.000000      0.000000          0.000000   \n4          0.000000      0.000000      0.000000          0.000000   \n...             ...           ...           ...               ...   \n62895      0.770324      0.229676      0.000000          0.000000   \n62896      0.000000      0.000000      0.978543          0.021457   \n62897      0.000000      0.116451      0.883549          0.000000   \n62898      0.000000      0.451245      0.000000          0.548755   \n62899      0.000000      0.000000      0.541944          0.458056   \n\n       ambulatory_1.0  ambulatory_UNKNOWN  ...  origin_9.0  origin_UNKNOWN  \\\n0                 0.0                 0.0  ...         0.0        1.000000   \n1                 0.0                 1.0  ...         0.0        1.000000   \n2                 0.0                 1.0  ...         0.0        1.000000   \n3                 0.0                 1.0  ...         0.0        1.000000   \n4                 0.0                 1.0  ...         0.0        1.000000   \n...               ...                 ...  ...         ...             ...   \n62895             0.0                 1.0  ...         0.0        0.229676   \n62896             0.0                 1.0  ...         0.0        0.021457   \n62897             0.0                 1.0  ...         0.0        1.000000   \n62898             0.0                 1.0  ...         0.0        1.000000   \n62899             0.0                 1.0  ...         0.0        1.000000   \n\n       tip_grd_Q  tip_grd_UNKNOWN  tip_adm_2.0  tip_adm_3.0  tip_adm_UNKNOWN  \\\n0       1.000000         0.000000          0.0          0.0         0.000000   \n1       1.000000         0.000000          0.0          0.0         0.000000   \n2       0.000000         1.000000          0.0          0.0         0.000000   \n3       1.000000         0.000000          0.0          0.0         1.000000   \n4       1.000000         0.000000          0.0          0.0         0.000000   \n...          ...              ...          ...          ...              ...   \n62895   0.000000         0.229676          0.0          0.0         0.000000   \n62896   0.000000         0.000000          0.0          0.0         0.978543   \n62897   0.883549         0.116451          0.0          0.0         0.116451   \n62898   0.000000         0.000000          0.0          0.0         0.548755   \n62899   0.000000         0.458056          0.0          0.0         0.541944   \n\n       exitus  dataset     date  \n0           0    train  2016-01  \n1           0    train  2016-01  \n2           0    train  2016-01  \n3           0    train  2016-01  \n4           0    train  2016-01  \n...       ...      ...      ...  \n62895       1      NaN      NaN  \n62896       1      NaN      NaN  \n62897       1      NaN      NaN  \n62898       1      NaN      NaN  \n62899       1      NaN      NaN  \n\n[62900 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>expected_length</th>\n      <th>num_proc</th>\n      <th>mortality_ratio</th>\n      <th>severity_2.0</th>\n      <th>severity_3.0</th>\n      <th>severity_4.0</th>\n      <th>severity_UNKNOWN</th>\n      <th>ambulatory_1.0</th>\n      <th>ambulatory_UNKNOWN</th>\n      <th>...</th>\n      <th>origin_9.0</th>\n      <th>origin_UNKNOWN</th>\n      <th>tip_grd_Q</th>\n      <th>tip_grd_UNKNOWN</th>\n      <th>tip_adm_2.0</th>\n      <th>tip_adm_3.0</th>\n      <th>tip_adm_UNKNOWN</th>\n      <th>exitus</th>\n      <th>dataset</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12596.000000</td>\n      <td>151.000000</td>\n      <td>21.000000</td>\n      <td>0.408730</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>train</td>\n      <td>2016-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20973.000000</td>\n      <td>99.000000</td>\n      <td>22.000000</td>\n      <td>0.306931</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>train</td>\n      <td>2016-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19611.000000</td>\n      <td>87.000000</td>\n      <td>19.000000</td>\n      <td>0.278481</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>train</td>\n      <td>2016-01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13583.000000</td>\n      <td>100.000000</td>\n      <td>22.000000</td>\n      <td>0.150289</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>train</td>\n      <td>2016-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>18042.000000</td>\n      <td>44.000000</td>\n      <td>2.000000</td>\n      <td>0.016573</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>train</td>\n      <td>2016-01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62895</th>\n      <td>22177.756113</td>\n      <td>13.554858</td>\n      <td>8.621943</td>\n      <td>0.091532</td>\n      <td>0.770324</td>\n      <td>0.229676</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.229676</td>\n      <td>0.000000</td>\n      <td>0.229676</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62896</th>\n      <td>25076.828341</td>\n      <td>5.935628</td>\n      <td>5.978543</td>\n      <td>0.532906</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.978543</td>\n      <td>0.021457</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.021457</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.978543</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62897</th>\n      <td>31820.349352</td>\n      <td>13.280959</td>\n      <td>7.116451</td>\n      <td>0.318403</td>\n      <td>0.000000</td>\n      <td>0.116451</td>\n      <td>0.883549</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.883549</td>\n      <td>0.116451</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.116451</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62898</th>\n      <td>33433.609957</td>\n      <td>7.804978</td>\n      <td>4.451245</td>\n      <td>0.041255</td>\n      <td>0.000000</td>\n      <td>0.451245</td>\n      <td>0.000000</td>\n      <td>0.548755</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.548755</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62899</th>\n      <td>32293.045267</td>\n      <td>5.877493</td>\n      <td>6.251662</td>\n      <td>0.153552</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.541944</td>\n      <td>0.458056</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.458056</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.541944</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>62900 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.981468300Z",
     "start_time": "2023-09-19T20:49:24.780367300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "y = dat['exitus']\n",
    "X = dat.drop(['exitus'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.982478500Z",
     "start_time": "2023-09-19T20:49:24.815457900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "dataset\ntrain    22894\ntest      4907\nval       4905\nName: count, dtype: int64"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['dataset'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.982478500Z",
     "start_time": "2023-09-19T20:49:24.822569200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [],
   "source": [
    "X_val = dat[dat['dataset'] == 'val'].drop(['dataset', 'date'], axis=1)\n",
    "y_val = dat[dat['dataset'] == 'val']['exitus']\n",
    "X_train = dat[dat['dataset'] == 'train'].drop(['dataset', 'date'], axis=1)\n",
    "y_train = dat[dat['dataset'] == 'train']['exitus']\n",
    "X_test = dat[dat['dataset'] == 'test'].drop(['dataset', 'date'], axis=1)\n",
    "y_test = dat[dat['dataset'] == 'test']['exitus']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:49:24.989478700Z",
     "start_time": "2023-09-19T20:49:24.838193800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [3] Create Model"
   ],
   "metadata": {
    "id": "5BczaKLlcKTl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as model_constructor\n",
    "from sklearn.metrics import roc_auc_score as metric\n",
    "\n",
    "# Random Forest\n",
    "n_estimators_values = [10, 100, 1000]\n",
    "max_features_values = [2, 5, 10]\n",
    "max_samples_values = [100, 1000, X_train.shape[0]]\n",
    "\n",
    "params_grid = {'max_features': max_features_values,\n",
    "              'n_estimators': n_estimators_values,\n",
    "               'max_samples': max_samples_values}\n",
    "\n",
    "num_iter = 1\n",
    "grid_results = pd.DataFrame(columns = ('max_features',\n",
    "                                       'n_estimators',\n",
    "                                       'max_samples',\n",
    "                                       'metric_train',\n",
    "                                       'metric_val'))\n",
    "\n",
    "for max_features in params_grid['max_features']:\n",
    "    for n_estimators in params_grid['n_estimators']:\n",
    "        for max_samples in params_grid['max_samples']:\n",
    "\n",
    "                        # Print trace\n",
    "                        print('Iteracion = ' + str(num_iter))\n",
    "\n",
    "                        # [3] Define model\n",
    "                        model = model_constructor(max_features = max_features,\n",
    "                                                  n_estimators = n_estimators,\n",
    "                                                  max_samples = max_samples,\n",
    "                                                  random_state = 0)\n",
    "\n",
    "                        # [4] Train model\n",
    "                        model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                        # [5] Predict\n",
    "                        pred_train = model.predict(X_train) # predict!\n",
    "                        pred_val = model.predict(X_val) # predict!\n",
    "\n",
    "                        # [6] Compute metric\n",
    "                        metric_train = metric(y_train, pred_train)\n",
    "                        metric_val = metric(y_val, pred_val)\n",
    "\n",
    "                        # print error\n",
    "                        print('Metric train = %.2f - Metric validation = %.2f.'\n",
    "                              % (metric_train, metric_val))\n",
    "\n",
    "                        # Save iteration results\n",
    "                        grid_results.loc[num_iter]=[ max_features,\n",
    "                                                    n_estimators,\n",
    "                                                    max_samples,\n",
    "                                                 metric_train,\n",
    "                                                 metric_val]\n",
    "                        num_iter += 1\n"
   ],
   "metadata": {
    "id": "YaAjN6unrxpN",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.012022800Z",
     "start_time": "2023-09-19T20:49:24.882226Z"
    }
   },
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion = 1\n",
      "Metric train = 0.63 - Metric validation = 0.65.\n",
      "Iteracion = 2\n",
      "Metric train = 0.96 - Metric validation = 0.95.\n",
      "Iteracion = 3\n",
      "Metric train = 1.00 - Metric validation = 0.99.\n",
      "Iteracion = 4\n",
      "Metric train = 0.67 - Metric validation = 0.64.\n",
      "Iteracion = 5\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 6\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 7\n",
      "Metric train = 0.61 - Metric validation = 0.58.\n",
      "Iteracion = 8\n",
      "Metric train = 1.00 - Metric validation = 0.99.\n",
      "Iteracion = 9\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 10\n",
      "Metric train = 0.90 - Metric validation = 0.88.\n",
      "Iteracion = 11\n",
      "Metric train = 1.00 - Metric validation = 0.99.\n",
      "Iteracion = 12\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 13\n",
      "Metric train = 0.98 - Metric validation = 0.99.\n",
      "Iteracion = 14\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 15\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 16\n",
      "Metric train = 0.97 - Metric validation = 0.96.\n",
      "Iteracion = 17\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 18\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 19\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 20\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 21\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 22\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 23\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 24\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 25\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 26\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n",
      "Iteracion = 27\n",
      "Metric train = 1.00 - Metric validation = 1.00.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "max_features       2.00000\nn_estimators     100.00000\nmax_samples     1000.00000\nmetric_train       0.99774\nmetric_val         1.00000\nName: 5, dtype: float64"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = grid_results.sort_values(by = ['metric_val', 'metric_train'], ascending = [False, True])\n",
    "best_model = grid_results.iloc[0]\n",
    "best_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.017349600Z",
     "start_time": "2023-09-19T20:50:15.013023100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old train data size = (22894, 23)\n",
      "Old train target size = (22894,)\n",
      "New train data size = (27799, 23)\n",
      "New train target size = (27799,)\n"
     ]
    }
   ],
   "source": [
    "print('Old train data size = ' + str(X_train.shape))\n",
    "print('Old train target size = ' + str(y_train.shape))\n",
    "\n",
    "# Combine train and validación\n",
    "X_train = np.concatenate((X_train, X_val), axis = 0)\n",
    "y_train = np.concatenate((y_train, y_val), axis = 0)\n",
    "\n",
    "print('New train data size = ' + str(X_train.shape))\n",
    "print('New train target size = ' + str(y_train.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.037171400Z",
     "start_time": "2023-09-19T20:50:15.019347900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model =  model_constructor(criterion = 'gini',\n",
    "                          max_depth = None,\n",
    "                          min_samples_split = 2,\n",
    "                          min_samples_leaf = 1,\n",
    "                          max_features = int(best_model.max_features),\n",
    "                          n_estimators =  int(best_model.n_estimators),\n",
    "                          max_samples = int(best_model.max_samples),\n",
    "                          random_state = 0) # Use same random_state as in training!!!"
   ],
   "metadata": {
    "id": "ZvVUKcO0k5dm",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.091290800Z",
     "start_time": "2023-09-19T20:50:15.038171100Z"
    }
   },
   "execution_count": 155,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [],
   "source": [
    "dat.drop('date', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.092459600Z",
     "start_time": "2023-09-19T20:50:15.054473900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {
    "id": "eAe2bKe7hK_c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# [4] Train model\n",
    "model.fit(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1), dat[dat['dataset'] == 'train'].exitus.values)\n",
    "\n",
    "\n",
    "# [5] Predict\n",
    "pred_train = model.predict_proba(dat[dat['dataset'] == 'train'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_val = model.predict_proba(dat[dat['dataset'] == 'val'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "pred_test = model.predict_proba(dat[dat['dataset'] == 'test'].drop(['exitus', 'dataset'], axis = 1)) # predict!\n",
    "\n",
    "\n",
    "# [6] Compute metric\n",
    "metric_train = metric(dat[dat['dataset'] == 'train'].exitus.values, pred_train[:,1])\n",
    "metric_val = metric(dat[dat['dataset'] == 'val'].exitus.values, pred_val[:,1])\n",
    "metric_test = metric(dat[dat['dataset'] == 'test'].exitus.values, pred_test[:,1])"
   ],
   "metadata": {
    "id": "I0mwZ7GQhMIn",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.587701300Z",
     "start_time": "2023-09-19T20:50:15.071755200Z"
    }
   },
   "execution_count": 157,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# print error\n",
    "print('Metric train = %.2f - Metric val = %.2f - Metric test = %.2f'\n",
    "      % (metric_train, metric_val, metric_test))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-EPli1DiYGX",
    "outputId": "8e007bc0-142b-424d-ea6c-bfdaae328444",
    "ExecuteTime": {
     "end_time": "2023-09-19T20:50:15.587701300Z",
     "start_time": "2023-09-19T20:50:15.565728400Z"
    }
   },
   "execution_count": 158,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric train = 0.96 - Metric val = 0.93 - Metric test = 0.93\n"
     ]
    }
   ]
  }
 ]
}
